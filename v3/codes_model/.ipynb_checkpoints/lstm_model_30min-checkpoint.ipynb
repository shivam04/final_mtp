{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Alk. Phosphate</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Total Bili</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>...</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>Arterial BP [Systolic]</th>\n",
       "      <th>Temperature C</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Previous WeightF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103116</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.445489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 11:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 11:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 10:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 10:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 09:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 09:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 08:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 08:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.349624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 07:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.349624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 07:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.349624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 06:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.349624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 06:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 05:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 05:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 04:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 04:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.379699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 03:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.390977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 03:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 02:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 02:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 01:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 12:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 01:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 13:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 14:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17</td>\n",
       "      <td>2 days 00:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17</td>\n",
       "      <td>2 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 23:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 23:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 22:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 22:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 21:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 21:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 20:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 20:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 19:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.409774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 19:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 18:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 18:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 17:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 17:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 16:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 16:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 15:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 15:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 14:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 13:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 00:30:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.409774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 12:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188427</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID                  TimeStamp  Albumin  Alk. Phosphate  ALT  AST  \\\n",
       "0           17  0 days 00:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "1           17  1 days 11:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "2           17  1 days 11:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "3           17  1 days 10:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "4           17  1 days 10:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "5           17  1 days 09:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "6           17  1 days 09:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "7           17  1 days 08:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "8           17  1 days 08:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "9           17  1 days 07:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "10          17  1 days 07:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "11          17  1 days 06:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "12          17  1 days 06:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "13          17  1 days 05:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "14          17  1 days 05:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "15          17  1 days 04:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "16          17  1 days 04:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "17          17  1 days 03:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "18          17  1 days 03:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "19          17  1 days 02:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "20          17  1 days 02:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "21          17  1 days 01:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "22          17  1 days 12:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "23          17  1 days 01:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "24          17  1 days 13:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "25          17  1 days 14:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "26          17  2 days 00:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "27          17  2 days 00:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "28          17  1 days 23:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "29          17  1 days 23:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "30          17  1 days 22:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "31          17  1 days 22:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "32          17  1 days 21:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "33          17  1 days 21:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "34          17  1 days 20:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "35          17  1 days 20:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "36          17  1 days 19:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "37          17  1 days 19:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "38          17  1 days 18:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "39          17  1 days 18:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "40          17  1 days 17:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "41          17  1 days 17:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "42          17  1 days 16:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "43          17  1 days 16:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "44          17  1 days 15:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "45          17  1 days 15:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "46          17  1 days 14:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "47          17  1 days 13:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "48          17  1 days 00:30:00.000000000      0.0             0.0  0.0  0.0   \n",
       "49          17  1 days 12:00:00.000000000      0.0             0.0  0.0  0.0   \n",
       "\n",
       "    Total Bili       BUN  Cholesterol  Creatinine        ...         \\\n",
       "0          0.0  0.060606          0.0    0.009424        ...          \n",
       "1          0.0  0.060606          0.0    0.008377        ...          \n",
       "2          0.0  0.060606          0.0    0.008377        ...          \n",
       "3          0.0  0.060606          0.0    0.008377        ...          \n",
       "4          0.0  0.060606          0.0    0.008377        ...          \n",
       "5          0.0  0.060606          0.0    0.008377        ...          \n",
       "6          0.0  0.060606          0.0    0.008377        ...          \n",
       "7          0.0  0.060606          0.0    0.008377        ...          \n",
       "8          0.0  0.060606          0.0    0.008377        ...          \n",
       "9          0.0  0.060606          0.0    0.008377        ...          \n",
       "10         0.0  0.060606          0.0    0.008377        ...          \n",
       "11         0.0  0.060606          0.0    0.008377        ...          \n",
       "12         0.0  0.060606          0.0    0.008377        ...          \n",
       "13         0.0  0.060606          0.0    0.008377        ...          \n",
       "14         0.0  0.060606          0.0    0.008377        ...          \n",
       "15         0.0  0.060606          0.0    0.008377        ...          \n",
       "16         0.0  0.060606          0.0    0.008377        ...          \n",
       "17         0.0  0.060606          0.0    0.008377        ...          \n",
       "18         0.0  0.060606          0.0    0.008377        ...          \n",
       "19         0.0  0.060606          0.0    0.008377        ...          \n",
       "20         0.0  0.060606          0.0    0.008377        ...          \n",
       "21         0.0  0.060606          0.0    0.008377        ...          \n",
       "22         0.0  0.060606          0.0    0.008377        ...          \n",
       "23         0.0  0.060606          0.0    0.008377        ...          \n",
       "24         0.0  0.060606          0.0    0.008377        ...          \n",
       "25         0.0  0.060606          0.0    0.008377        ...          \n",
       "26         0.0  0.060606          0.0    0.008377        ...          \n",
       "27         0.0  0.060606          0.0    0.008377        ...          \n",
       "28         0.0  0.060606          0.0    0.008377        ...          \n",
       "29         0.0  0.060606          0.0    0.008377        ...          \n",
       "30         0.0  0.060606          0.0    0.008377        ...          \n",
       "31         0.0  0.060606          0.0    0.008377        ...          \n",
       "32         0.0  0.060606          0.0    0.008377        ...          \n",
       "33         0.0  0.060606          0.0    0.008377        ...          \n",
       "34         0.0  0.060606          0.0    0.008377        ...          \n",
       "35         0.0  0.060606          0.0    0.008377        ...          \n",
       "36         0.0  0.060606          0.0    0.008377        ...          \n",
       "37         0.0  0.060606          0.0    0.008377        ...          \n",
       "38         0.0  0.060606          0.0    0.008377        ...          \n",
       "39         0.0  0.060606          0.0    0.008377        ...          \n",
       "40         0.0  0.060606          0.0    0.008377        ...          \n",
       "41         0.0  0.060606          0.0    0.008377        ...          \n",
       "42         0.0  0.060606          0.0    0.008377        ...          \n",
       "43         0.0  0.060606          0.0    0.008377        ...          \n",
       "44         0.0  0.060606          0.0    0.008377        ...          \n",
       "45         0.0  0.060606          0.0    0.008377        ...          \n",
       "46         0.0  0.060606          0.0    0.008377        ...          \n",
       "47         0.0  0.060606          0.0    0.008377        ...          \n",
       "48         0.0  0.060606          0.0    0.008377        ...          \n",
       "49         0.0  0.060606          0.0    0.008377        ...          \n",
       "\n",
       "    Platelets  Respiratory Rate      SaO2  Arterial BP [Systolic]  \\\n",
       "0    0.103116          0.143564  0.990099                0.445489   \n",
       "1    0.188427          0.188119  0.980198                0.375940   \n",
       "2    0.188427          0.188119  0.980198                0.375940   \n",
       "3    0.188427          0.188119  0.980198                0.375940   \n",
       "4    0.188427          0.178218  0.980198                0.357143   \n",
       "5    0.188427          0.178218  0.980198                0.357143   \n",
       "6    0.188427          0.178218  0.980198                0.357143   \n",
       "7    0.188427          0.178218  0.980198                0.357143   \n",
       "8    0.188427          0.158416  0.980198                0.349624   \n",
       "9    0.188427          0.158416  0.980198                0.349624   \n",
       "10   0.188427          0.158416  0.980198                0.349624   \n",
       "11   0.188427          0.158416  0.980198                0.349624   \n",
       "12   0.188427          0.178218  0.980198                0.406015   \n",
       "13   0.188427          0.178218  0.980198                0.406015   \n",
       "14   0.188427          0.217822  0.980198                0.413534   \n",
       "15   0.188427          0.217822  0.940594                0.413534   \n",
       "16   0.188427          0.207921  0.940594                0.379699   \n",
       "17   0.188427          0.277228  0.940594                0.390977   \n",
       "18   0.188427          0.257426  0.940594                0.421053   \n",
       "19   0.188427          0.257426  0.940594                0.421053   \n",
       "20   0.188427          0.257426  0.940594                0.421053   \n",
       "21   0.188427          0.257426  0.940594                0.421053   \n",
       "22   0.188427          0.247525  0.980198                0.383459   \n",
       "23   0.188427          0.306931  0.940594                0.375940   \n",
       "24   0.188427          0.198020  0.980198                0.406015   \n",
       "25   0.188427          0.217822  0.980198                0.406015   \n",
       "26   0.188427          0.316832  0.980198                0.421053   \n",
       "27   0.188427          0.316832  0.980198                0.421053   \n",
       "28   0.188427          0.316832  0.980198                0.421053   \n",
       "29   0.188427          0.316832  0.980198                0.421053   \n",
       "30   0.188427          0.316832  0.980198                0.421053   \n",
       "31   0.188427          0.336634  0.980198                0.421053   \n",
       "32   0.188427          0.336634  0.980198                0.421053   \n",
       "33   0.188427          0.297030  0.980198                0.421053   \n",
       "34   0.188427          0.297030  0.980198                0.421053   \n",
       "35   0.188427          0.306931  0.980198                0.406015   \n",
       "36   0.188427          0.297030  0.980198                0.409774   \n",
       "37   0.188427          0.316832  0.980198                0.413534   \n",
       "38   0.188427          0.356436  0.980198                0.402256   \n",
       "39   0.188427          0.356436  0.980198                0.402256   \n",
       "40   0.188427          0.356436  0.980198                0.402256   \n",
       "41   0.188427          0.301980  0.980198                0.368421   \n",
       "42   0.188427          0.301980  0.980198                0.368421   \n",
       "43   0.188427          0.301980  0.980198                0.368421   \n",
       "44   0.188427          0.301980  0.980198                0.428571   \n",
       "45   0.188427          0.301980  0.980198                0.428571   \n",
       "46   0.188427          0.217822  0.980198                0.406015   \n",
       "47   0.188427          0.198020  0.980198                0.406015   \n",
       "48   0.188427          0.227723  0.940594                0.409774   \n",
       "49   0.188427          0.247525  0.980198                0.383459   \n",
       "\n",
       "    Temperature C  TroponinI  TroponinT  Urine       WBC  Previous WeightF  \n",
       "0             0.0        0.0        0.0    0.0  0.021739               0.0  \n",
       "1             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "2             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "3             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "4             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "5             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "6             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "7             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "8             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "9             0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "10            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "11            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "12            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "13            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "14            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "15            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "16            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "17            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "18            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "19            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "20            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "21            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "22            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "23            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "24            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "25            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "26            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "27            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "28            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "29            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "30            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "31            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "32            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "33            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "34            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "35            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "36            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "37            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "38            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "39            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "40            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "41            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "42            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "43            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "44            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "45            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "46            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "47            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "48            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "49            0.0        0.0        0.0    0.0  0.040076               0.0  \n",
       "\n",
       "[50 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finalset/patient_data_4830_hours.csv')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = df.groupby('SUBJECT_ID')\n",
    "p = []\n",
    "for s,g in ff:\n",
    "    p.append((s,len(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in p:\n",
    "    if g[1]!=98:\n",
    "        print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.02173913,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04007561,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04007561,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.79032258, 0.        , 0.00204374, ..., 0.        , 0.01039698,\n",
       "        0.        ],\n",
       "       [0.79032258, 0.        , 0.00204374, ..., 0.        , 0.01039698,\n",
       "        0.        ],\n",
       "       [0.79032258, 0.        , 0.00204374, ..., 0.        , 0.01342155,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D = np.array(df.drop(['SUBJECT_ID', 'TimeStamp'], 1))\n",
    "matrix3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645526, 37)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 98, 37)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D = np.array(matrix3D).reshape((6587, 98, 37))\n",
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  LABEL\n",
       "0          17      0\n",
       "1          21      0\n",
       "2          23      0\n",
       "3          34      0\n",
       "4          36      1\n",
       "5          61      0\n",
       "6          68      1\n",
       "7          85      0\n",
       "8          94      0\n",
       "9         103      1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = pd.read_csv('finalset/outcomes.csv')\n",
    "outcomes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(outcomes.drop(['SUBJECT_ID'], 1))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 98, 37)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = matrix3D\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X,X))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13174, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate((Y,Y))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26348, 98, 37)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X,X))\n",
    "#X = np.concatenate((X,X))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26348, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate((Y,Y))\n",
    "#Y = np.concatenate((Y,Y))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 1, 98, 37)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X.reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6587, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_new = Y.reshape(Y.shape[0],1,Y.shape[1])\n",
    "print(Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 2, 98, 37)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.insert(X_new, 1, Y_new, axis=1)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 2, 98, 37)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(X_new)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 98, 37)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_new[:,0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = X_new[:,1]\n",
    "Y = Y[:,0]\n",
    "Y = Y[:,0]\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 98, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1787, 98, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4800, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1787, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X[:4800]\n",
    "X_test = X[4800:]\n",
    "Y_train = Y[:4800]\n",
    "Y_test = Y[4800:]\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1, 98, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1787, 1, 98, 37)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X_train.reshape((X_train.shape[0],1,X_train.shape[1],X_train.shape[2]))\n",
    "X_te = X_test.reshape((X_test.shape[0],1,X_test.shape[1],X_test.shape[2]))\n",
    "display(X_tr.shape)\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.2209622 ]],\n",
       " \n",
       "        [[0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ],\n",
       "         [0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ],\n",
       "         [0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ],\n",
       "         ...,\n",
       "         [0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ],\n",
       "         [0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ],\n",
       "         [0.70967742, 0.        , 0.00173718, ..., 0.        ,\n",
       "          0.01247637, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.28316152],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.32233678],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.32233678],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.28316152],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.28316152],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.02741021, 0.28316152]],\n",
       " \n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ],\n",
       "         [0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ],\n",
       "         [0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ],\n",
       "         ...,\n",
       "         [0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ],\n",
       "         [0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ],\n",
       "         [0.74193548, 0.02118335, 0.0038831 , ..., 0.        ,\n",
       "          0.01833648, 0.        ]]]), array([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]), array([[[0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 3.42155009e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 3.42155009e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 3.42155009e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 2.85444234e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 2.57088847e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15307582e-04, ...,\n",
       "          0.00000000e+00, 2.85444234e-02, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.78071834e-02, 3.62886593e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.78071834e-02, 3.62886593e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.78071834e-02, 3.62886593e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.96975425e-02, 3.62886593e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.78071834e-02, 3.62886593e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.96975425e-02, 3.62886593e-01]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.87145558e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.87145558e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.87145558e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.83364839e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.83364839e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.13427345e-02, ...,\n",
       "          0.00000000e+00, 1.83364839e-02, 0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.15879017e-02, 0.00000000e+00],\n",
       "         [8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.15879017e-02, 0.00000000e+00],\n",
       "         [8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.15879017e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.51606805e-02, 0.00000000e+00],\n",
       "         [8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.51606805e-02, 0.00000000e+00],\n",
       "         [8.06451613e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.15879017e-02, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.38374291e-02, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.16151203e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.16151203e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.16151203e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.19243991e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.19243991e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.19243991e-01]]]), array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [X_train,Y_train,X_test,Y_test]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finalset/datasets_og.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1825.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([636.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 98, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24000, 98, 37)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainr = np.concatenate((X_train,X_train))\n",
    "X_trainr = np.concatenate((X_trainr,X_trainr))\n",
    "X_trainr = np.concatenate((X_trainr,X_train))\n",
    "display(X_train.shape)\n",
    "X_trainr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24000, 1)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainr = np.concatenate((Y_train,Y_train))\n",
    "Y_trainr = np.concatenate((Y_trainr,Y_trainr))\n",
    "Y_trainr = np.concatenate((Y_trainr,Y_train))\n",
    "display(Y_train.shape)\n",
    "Y_trainr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3574, 1)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_testr = np.concatenate((Y_test,Y_test))\n",
    "Y_testr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3574, 98, 37)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testr = np.concatenate((X_test,X_test))\n",
    "X_testr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 98, 32)            5952      \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 98, 32)            5152      \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 98, 64)            10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 98, 128)           20608     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 98, 128)           41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_117 (LSTM)              (None, 98, 128)           98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (None, 98, 128)           98816     \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_36 (Bidirectio (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 659,169\n",
      "Trainable params: 659,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 3574 samples\n",
      "Epoch 1/10\n",
      "24000/24000 [==============================] - 123s 5ms/step - loss: 0.6639 - acc: 0.6148 - val_loss: 0.6492 - val_acc: 0.6441\n",
      "Epoch 2/10\n",
      "24000/24000 [==============================] - 101s 4ms/step - loss: 0.6545 - acc: 0.6198 - val_loss: 0.6549 - val_acc: 0.6363\n",
      "Epoch 3/10\n",
      "24000/24000 [==============================] - 98s 4ms/step - loss: 0.6446 - acc: 0.6355 - val_loss: 0.6378 - val_acc: 0.6603\n",
      "Epoch 4/10\n",
      "24000/24000 [==============================] - 101s 4ms/step - loss: 0.6393 - acc: 0.6387 - val_loss: 0.6501 - val_acc: 0.6419\n",
      "Epoch 5/10\n",
      "24000/24000 [==============================] - 99s 4ms/step - loss: 0.6334 - acc: 0.6452 - val_loss: 0.6449 - val_acc: 0.6514\n",
      "Epoch 6/10\n",
      "24000/24000 [==============================] - 145s 6ms/step - loss: 0.6299 - acc: 0.6482 - val_loss: 0.6480 - val_acc: 0.6530\n",
      "Epoch 7/10\n",
      "24000/24000 [==============================] - 213s 9ms/step - loss: 0.6276 - acc: 0.6489 - val_loss: 0.6599 - val_acc: 0.6424\n",
      "Epoch 8/10\n",
      "24000/24000 [==============================] - 267s 11ms/step - loss: 0.6331 - acc: 0.6422 - val_loss: 0.6627 - val_acc: 0.6407\n",
      "Epoch 9/10\n",
      "24000/24000 [==============================] - 281s 12ms/step - loss: 0.6788 - acc: 0.6045 - val_loss: 0.6490 - val_acc: 0.6452\n",
      "Epoch 10/10\n",
      "24000/24000 [==============================] - 265s 11ms/step - loss: 0.6605 - acc: 0.6171 - val_loss: 0.6495 - val_acc: 0.6441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bd6607a90>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Reshape,MaxPooling1D,Conv1D\n",
    "model8ecw = Sequential()\n",
    "model8ecw.add(Conv1D(32, kernel_size=5, input_shape=(X_train.shape[1],X_train.shape[2]), activation='relu', padding='same',data_format=\"channels_last\"))\n",
    "model8ecw.add(Conv1D(32, 5, activation='relu', padding='same'))\n",
    "model8ecw.add(Conv1D(64, 5, activation='relu', padding='same'))\n",
    "model8ecw.add(MaxPooling1D(pool_size=2,data_format=\"channels_first\"))\n",
    "model8ecw.add(Conv1D(128, 5, activation='relu', padding='same'))\n",
    "model8ecw.add(MaxPooling1D(pool_size=2,data_format=\"channels_first\"))\n",
    "model8ecw.add(Conv1D(128, 5, activation='relu', padding='same'))\n",
    "model8ecw.add(MaxPooling1D(pool_size=2,data_format=\"channels_first\"))\n",
    "#model8ecw.add(Reshape((98,100)))\n",
    "model8ecw.add(LSTM(128,input_shape=(98,64),activation='relu',return_sequences=True))\n",
    "model8ecw.add(Bidirectional(LSTM(64,activation='relu',return_sequences=True)))\n",
    "model8ecw.add(Dropout(0.2))\n",
    "model8ecw.add(Bidirectional(LSTM(32,activation='relu')))\n",
    "model8ecw.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "model8ecw.add(Dense(1024,activation='tanh'))\n",
    "model8ecw.add(Dropout(0.2))\n",
    "model8ecw.add(Dense(256,activation='tanh'))\n",
    "model8ecw.add(Dropout(0.2))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "model8ecw.add(Dense(32,activation='tanh'))\n",
    "model8ecw.add(Dense(1, activation='sigmoid'))\n",
    "model8ecw.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "display(model8ecw.summary())\n",
    "model8ecw.fit(X_trainr, Y_trainr, validation_data=(X_testr, Y_testr), epochs=10,batch_size=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.03245660454185"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8ecw.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 9s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.40962507662056"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8ecw.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#save keras model\n",
    "model_json = model8ecw.to_json()\n",
    "with open(\"models/vdeepconvblstm4timestrain.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model8ecw.save_weights(\"models/vdeepconvblstm4timestrain.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Add\n",
    "from keras.layers import Dropout,Bidirectional,BatchNormalization,Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 98, 100)           52400     \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 90,496\n",
      "Trainable params: 90,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 95000 samples, validate on 10392 samples\n",
      "Epoch 1/30\n",
      "95000/95000 [==============================] - 127s 1ms/step - loss: 0.6448 - acc: 0.6402 - val_loss: 0.6422 - val_acc: 0.6382\n",
      "Epoch 2/30\n",
      "95000/95000 [==============================] - 70s 740us/step - loss: 0.6394 - acc: 0.6433 - val_loss: 0.6396 - val_acc: 0.6402\n",
      "Epoch 3/30\n",
      "95000/95000 [==============================] - 95s 997us/step - loss: 0.6363 - acc: 0.6458 - val_loss: 0.6358 - val_acc: 0.6442\n",
      "Epoch 4/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6304 - acc: 0.6515 - val_loss: 0.6355 - val_acc: 0.6447\n",
      "Epoch 5/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6263 - acc: 0.6547 - val_loss: 0.6297 - val_acc: 0.6493\n",
      "Epoch 6/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6225 - acc: 0.6566 - val_loss: 0.6287 - val_acc: 0.6481\n",
      "Epoch 7/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6174 - acc: 0.6614 - val_loss: 0.6215 - val_acc: 0.6591\n",
      "Epoch 8/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6135 - acc: 0.6631 - val_loss: 0.6129 - val_acc: 0.6599\n",
      "Epoch 9/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.6104 - acc: 0.6659 - val_loss: 0.6088 - val_acc: 0.6576\n",
      "Epoch 10/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.5995 - acc: 0.6715 - val_loss: 0.6128 - val_acc: 0.6603\n",
      "Epoch 11/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.5940 - acc: 0.6733 - val_loss: 0.5945 - val_acc: 0.6694\n",
      "Epoch 12/30\n",
      "95000/95000 [==============================] - 95s 1000us/step - loss: 0.5900 - acc: 0.6770 - val_loss: 0.5910 - val_acc: 0.6745\n",
      "Epoch 13/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.5797 - acc: 0.6861 - val_loss: 0.5711 - val_acc: 0.6869\n",
      "Epoch 14/30\n",
      "95000/95000 [==============================] - 95s 998us/step - loss: 0.5609 - acc: 0.6978 - val_loss: 0.5569 - val_acc: 0.6950\n",
      "Epoch 15/30\n",
      "95000/95000 [==============================] - 95s 998us/step - loss: 0.5611 - acc: 0.6992 - val_loss: 0.5490 - val_acc: 0.6941\n",
      "Epoch 16/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.5414 - acc: 0.7095 - val_loss: 0.5507 - val_acc: 0.7034\n",
      "Epoch 17/30\n",
      "95000/95000 [==============================] - 95s 998us/step - loss: 0.5413 - acc: 0.7104 - val_loss: 0.5453 - val_acc: 0.7024\n",
      "Epoch 18/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.5272 - acc: 0.7187 - val_loss: 0.5229 - val_acc: 0.7147\n",
      "Epoch 19/30\n",
      "95000/95000 [==============================] - 95s 996us/step - loss: 0.5208 - acc: 0.7226 - val_loss: 0.5212 - val_acc: 0.7181\n",
      "Epoch 20/30\n",
      "95000/95000 [==============================] - 95s 999us/step - loss: 0.4952 - acc: 0.7378 - val_loss: 0.5009 - val_acc: 0.7314\n",
      "Epoch 21/30\n",
      "95000/95000 [==============================] - 95s 997us/step - loss: 0.5076 - acc: 0.7328 - val_loss: 0.4829 - val_acc: 0.7466\n",
      "Epoch 22/30\n",
      "95000/95000 [==============================] - 95s 1ms/step - loss: 0.4804 - acc: 0.7478 - val_loss: 0.4973 - val_acc: 0.7345\n",
      "Epoch 23/30\n",
      "95000/95000 [==============================] - 95s 1000us/step - loss: 0.4569 - acc: 0.7607 - val_loss: 0.4514 - val_acc: 0.7617\n",
      "Epoch 24/30\n",
      "95000/95000 [==============================] - 70s 734us/step - loss: 0.4643 - acc: 0.7593 - val_loss: 0.4402 - val_acc: 0.7668\n",
      "Epoch 25/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.4387 - acc: 0.7745 - val_loss: 0.4393 - val_acc: 0.7742\n",
      "Epoch 26/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.4219 - acc: 0.7819 - val_loss: 0.4166 - val_acc: 0.7861\n",
      "Epoch 27/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.4010 - acc: 0.7945 - val_loss: 0.3948 - val_acc: 0.7915\n",
      "Epoch 28/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.3872 - acc: 0.8029 - val_loss: 0.5728 - val_acc: 0.7396\n",
      "Epoch 29/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.4483 - acc: 0.7716 - val_loss: 0.3995 - val_acc: 0.7924\n",
      "Epoch 30/30\n",
      "95000/95000 [==============================] - 57s 604us/step - loss: 0.3875 - acc: 0.8025 - val_loss: 0.3938 - val_acc: 0.7984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f818ef4bc18>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "model8.add(LSTM(50))\n",
    "model8.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "model8.add(Dense(100,activation='tanh'))\n",
    "model8.add(Dense(25,activation='tanh'))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "model8.add(Dense(10,activation='tanh'))\n",
    "model8.add(Dense(1, activation='sigmoid'))\n",
    "model8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model8.summary())\n",
    "model8.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 9s 828us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.84026174438836"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.545015  ],\n",
       "       [0.05126255],\n",
       "       [0.34637684],\n",
       "       ...,\n",
       "       [0.3327171 ],\n",
       "       [0.35958487],\n",
       "       [0.36133274]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model8.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1200871696311796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6649608188069727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0.77203874, 0.88922156]),\n",
       " array([0.96001235, 0.53103448]),\n",
       " array([0.85582548, 0.66496082]),\n",
       " array([6477, 3915]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7984026173979984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7603931476871557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[6218,  259],\n",
       "       [1836, 2079]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8799128303688204,  Score/Loss : 0.1200871696311796, F1_Score_average: 0.6649608188069727, Precision, Recall, F1_score, Support: (array([0.77203874, 0.88922156]), array([0.96001235, 0.53103448]), array([0.85582548, 0.66496082]), array([6477, 3915]))\n",
      "F1_score_micro: 0.7984026173979984\n",
      "F1_score_macro: 0.7603931476871557\n",
      "Confusion Matrix\n",
      "[[6218  259]\n",
      " [1836 2079]]\n",
      "END\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 1.0 - roc_auc_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "display(score)\n",
    "\n",
    "\n",
    "f_score=f1_score(Y_test,y_pred.round())\n",
    "\n",
    "display(f_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prfs=precision_recall_fscore_support(Y_test,y_pred.round())\n",
    "\n",
    "\n",
    "display(prfs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_score_micro=f1_score(Y_test,y_pred.round(),average='micro')\n",
    "f_score_macro=f1_score(Y_test,y_pred.round(),average='macro')\n",
    "\n",
    "display(f_score_micro)\n",
    "display(f_score_macro)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf=confusion_matrix(Y_test,y_pred.round())\n",
    "\n",
    "display(cf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUC : \"+str(1.0 - score)+\",  Score/Loss : \"+str(score)+\", F1_Score_average: \"+str(f_score)+\", Precision, Recall, F1_score, Support: \"+str(prfs))\n",
    "print(\"F1_score_micro: \"+str(f_score_micro))\n",
    "print(\"F1_score_macro: \"+str(f_score_macro))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cf)\n",
    "print(\"END\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.8799128303688204}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# In[271]:\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[1], tpr[1], _ = roc_curve(Y_test[:, 0], y_pred[:, 0])\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])\n",
    "\n",
    "\n",
    "# In[272]:\n",
    "\n",
    "\n",
    "display(roc_auc)\n",
    "\n",
    "\n",
    "# In[275]:\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('finalset/datasets_16times.pickle', 'rb') as handle:\n",
    "    [X_train,  Y_train,X_test,Y_test] = pickle.load(handle)\n",
    "    print(\"yes\")\n",
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(95000, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47000, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(47000, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_train[:47000]\n",
    "Y_train = Y_train[:47000]\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 98, 100)           52400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50)                25200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 85,496\n",
      "Trainable params: 85,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 47000 samples, validate on 10392 samples\n",
      "Epoch 1/30\n",
      "47000/47000 [==============================] - 40s 857us/step - loss: 0.6533 - acc: 0.6323 - val_loss: 0.6449 - val_acc: 0.6385\n",
      "Epoch 2/30\n",
      "47000/47000 [==============================] - 39s 820us/step - loss: 0.6435 - acc: 0.6391 - val_loss: 0.6438 - val_acc: 0.6367\n",
      "Epoch 3/30\n",
      "47000/47000 [==============================] - 38s 805us/step - loss: 0.6407 - acc: 0.6400 - val_loss: 0.6418 - val_acc: 0.6374\n",
      "Epoch 4/30\n",
      "47000/47000 [==============================] - 38s 800us/step - loss: 0.6391 - acc: 0.6419 - val_loss: 0.6390 - val_acc: 0.6441\n",
      "Epoch 5/30\n",
      "47000/47000 [==============================] - 38s 810us/step - loss: 0.6354 - acc: 0.6464 - val_loss: 0.6405 - val_acc: 0.6407\n",
      "Epoch 6/30\n",
      "47000/47000 [==============================] - 38s 814us/step - loss: 0.6347 - acc: 0.6461 - val_loss: 0.6362 - val_acc: 0.6458\n",
      "Epoch 7/30\n",
      "47000/47000 [==============================] - 37s 791us/step - loss: 0.6328 - acc: 0.6488 - val_loss: 0.6357 - val_acc: 0.6450\n",
      "Epoch 8/30\n",
      "47000/47000 [==============================] - 37s 790us/step - loss: 0.6316 - acc: 0.6491 - val_loss: 0.6347 - val_acc: 0.6472\n",
      "Epoch 9/30\n",
      "47000/47000 [==============================] - 37s 790us/step - loss: 0.6317 - acc: 0.6478 - val_loss: 0.6366 - val_acc: 0.6444\n",
      "Epoch 10/30\n",
      "47000/47000 [==============================] - 37s 793us/step - loss: 0.6297 - acc: 0.6495 - val_loss: 0.6331 - val_acc: 0.6463\n",
      "Epoch 11/30\n",
      "47000/47000 [==============================] - 37s 793us/step - loss: 0.6270 - acc: 0.6523 - val_loss: 0.6325 - val_acc: 0.6465\n",
      "Epoch 12/30\n",
      "47000/47000 [==============================] - 37s 790us/step - loss: 0.6260 - acc: 0.6548 - val_loss: 0.6316 - val_acc: 0.6498\n",
      "Epoch 13/30\n",
      "47000/47000 [==============================] - 37s 790us/step - loss: 0.6238 - acc: 0.6557 - val_loss: 0.6253 - val_acc: 0.6547\n",
      "Epoch 14/30\n",
      "47000/47000 [==============================] - 37s 790us/step - loss: 0.6166 - acc: 0.6616 - val_loss: 0.6256 - val_acc: 0.6529\n",
      "Epoch 15/30\n",
      "47000/47000 [==============================] - 37s 792us/step - loss: 0.6155 - acc: 0.6627 - val_loss: 0.6191 - val_acc: 0.6593\n",
      "Epoch 16/30\n",
      "47000/47000 [==============================] - 37s 793us/step - loss: 0.6136 - acc: 0.6649 - val_loss: 0.6211 - val_acc: 0.6564\n",
      "Epoch 17/30\n",
      "47000/47000 [==============================] - 37s 794us/step - loss: 0.6123 - acc: 0.6654 - val_loss: 0.6193 - val_acc: 0.6562\n",
      "Epoch 18/30\n",
      "47000/47000 [==============================] - 37s 793us/step - loss: 0.6099 - acc: 0.6670 - val_loss: 0.6189 - val_acc: 0.6563\n",
      "Epoch 19/30\n",
      "47000/47000 [==============================] - 37s 795us/step - loss: 0.6039 - acc: 0.6732 - val_loss: 0.6136 - val_acc: 0.6602\n",
      "Epoch 20/30\n",
      "47000/47000 [==============================] - 40s 842us/step - loss: 0.6001 - acc: 0.6731 - val_loss: 0.6056 - val_acc: 0.6693\n",
      "Epoch 21/30\n",
      "47000/47000 [==============================] - 39s 832us/step - loss: 0.6001 - acc: 0.6741 - val_loss: 0.6117 - val_acc: 0.6644\n",
      "Epoch 22/30\n",
      "47000/47000 [==============================] - 40s 844us/step - loss: 0.5954 - acc: 0.6774 - val_loss: 0.6019 - val_acc: 0.6716\n",
      "Epoch 23/30\n",
      "47000/47000 [==============================] - 40s 850us/step - loss: 0.5866 - acc: 0.6810 - val_loss: 0.6072 - val_acc: 0.6658\n",
      "Epoch 24/30\n",
      "47000/47000 [==============================] - 40s 852us/step - loss: 0.5896 - acc: 0.6799 - val_loss: 0.5955 - val_acc: 0.6768\n",
      "Epoch 25/30\n",
      "47000/47000 [==============================] - 39s 831us/step - loss: 0.5752 - acc: 0.6877 - val_loss: 0.5862 - val_acc: 0.6715\n",
      "Epoch 26/30\n",
      "47000/47000 [==============================] - 41s 865us/step - loss: 0.5719 - acc: 0.6919 - val_loss: 0.5816 - val_acc: 0.6797\n",
      "Epoch 27/30\n",
      "47000/47000 [==============================] - 40s 851us/step - loss: 0.5632 - acc: 0.7003 - val_loss: 0.5692 - val_acc: 0.6867\n",
      "Epoch 28/30\n",
      "47000/47000 [==============================] - 39s 826us/step - loss: 0.5589 - acc: 0.6999 - val_loss: 0.5720 - val_acc: 0.6942\n",
      "Epoch 29/30\n",
      "47000/47000 [==============================] - 38s 816us/step - loss: 0.5601 - acc: 0.7014 - val_loss: 0.5650 - val_acc: 0.6887\n",
      "Epoch 30/30\n",
      "47000/47000 [==============================] - 39s 832us/step - loss: 0.5534 - acc: 0.7042 - val_loss: 0.5952 - val_acc: 0.6771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c4d3afcf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8e = Sequential()\n",
    "model8e.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "model8e.add(Bidirectional(LSTM(25)))\n",
    "model8e.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "model8e.add(Dense(100,activation='tanh'))\n",
    "model8e.add(Dense(25,activation='tanh'))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "model8e.add(Dense(10,activation='tanh'))\n",
    "model8e.add(Dense(1, activation='sigmoid'))\n",
    "model8e.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model8e.summary())\n",
    "model8e.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 8s 726us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.70592763205508"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8e.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47000, 1, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 1, 98, 30)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X_train.reshape((X_train.shape[0],1,X_train.shape[1],X_train.shape[2]))\n",
    "X_te = X_test.reshape((X_test.shape[0],1,X_test.shape[1],X_test.shape[2]))\n",
    "display(X_tr.shape)\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47000, 1, 98, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10392, 1, 98, 30)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_tr.shape)\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 1, 98, 45)         33795     \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 98, 45)            0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 100)               58400     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 105,091\n",
      "Trainable params: 105,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47000 samples, validate on 10392 samples\n",
      "Epoch 1/30\n",
      "47000/47000 [==============================] - 28s 594us/step - loss: 0.6514 - acc: 0.6333 - val_loss: 0.6424 - val_acc: 0.6381\n",
      "Epoch 2/30\n",
      "47000/47000 [==============================] - 26s 558us/step - loss: 0.6400 - acc: 0.6406 - val_loss: 0.6424 - val_acc: 0.6390\n",
      "Epoch 3/30\n",
      "47000/47000 [==============================] - 26s 557us/step - loss: 0.6392 - acc: 0.6403 - val_loss: 0.6398 - val_acc: 0.6379\n",
      "Epoch 4/30\n",
      "47000/47000 [==============================] - 26s 562us/step - loss: 0.6339 - acc: 0.6457 - val_loss: 0.6352 - val_acc: 0.6450\n",
      "Epoch 5/30\n",
      "47000/47000 [==============================] - 27s 566us/step - loss: 0.6294 - acc: 0.6489 - val_loss: 0.6313 - val_acc: 0.6448\n",
      "Epoch 6/30\n",
      "47000/47000 [==============================] - 25s 529us/step - loss: 0.6293 - acc: 0.6496 - val_loss: 0.6345 - val_acc: 0.6480\n",
      "Epoch 7/30\n",
      "47000/47000 [==============================] - 24s 515us/step - loss: 0.6290 - acc: 0.6510 - val_loss: 0.6319 - val_acc: 0.6470\n",
      "Epoch 8/30\n",
      "47000/47000 [==============================] - 31s 655us/step - loss: 0.6229 - acc: 0.6556 - val_loss: 0.6300 - val_acc: 0.6482\n",
      "Epoch 9/30\n",
      "47000/47000 [==============================] - 35s 743us/step - loss: 0.6199 - acc: 0.6564 - val_loss: 0.6255 - val_acc: 0.6511\n",
      "Epoch 10/30\n",
      "47000/47000 [==============================] - 35s 751us/step - loss: 0.6165 - acc: 0.6595 - val_loss: 0.6224 - val_acc: 0.6527\n",
      "Epoch 11/30\n",
      "47000/47000 [==============================] - 35s 737us/step - loss: 0.6133 - acc: 0.6607 - val_loss: 0.6145 - val_acc: 0.6588\n",
      "Epoch 12/30\n",
      "47000/47000 [==============================] - 36s 768us/step - loss: 0.6433 - acc: 0.6410 - val_loss: 0.6390 - val_acc: 0.6386\n",
      "Epoch 13/30\n",
      "47000/47000 [==============================] - 35s 735us/step - loss: 0.6305 - acc: 0.6434 - val_loss: 0.6255 - val_acc: 0.6465\n",
      "Epoch 14/30\n",
      "47000/47000 [==============================] - 35s 739us/step - loss: 0.6191 - acc: 0.6556 - val_loss: 0.6196 - val_acc: 0.6545\n",
      "Epoch 15/30\n",
      "47000/47000 [==============================] - 36s 775us/step - loss: 0.6106 - acc: 0.6617 - val_loss: 0.6299 - val_acc: 0.6372\n",
      "Epoch 16/30\n",
      "47000/47000 [==============================] - 36s 772us/step - loss: 0.6065 - acc: 0.6668 - val_loss: 0.6122 - val_acc: 0.6617\n",
      "Epoch 17/30\n",
      "47000/47000 [==============================] - 35s 739us/step - loss: 0.6015 - acc: 0.6695 - val_loss: 0.6084 - val_acc: 0.6633\n",
      "Epoch 18/30\n",
      "47000/47000 [==============================] - 39s 820us/step - loss: 0.5925 - acc: 0.6768 - val_loss: 0.6023 - val_acc: 0.6681\n",
      "Epoch 19/30\n",
      "47000/47000 [==============================] - 38s 817us/step - loss: 0.5889 - acc: 0.6802 - val_loss: 0.6009 - val_acc: 0.6681\n",
      "Epoch 20/30\n",
      "47000/47000 [==============================] - 36s 765us/step - loss: 0.5886 - acc: 0.6809 - val_loss: 0.5965 - val_acc: 0.6717\n",
      "Epoch 21/30\n",
      "47000/47000 [==============================] - 36s 764us/step - loss: 0.5832 - acc: 0.6836 - val_loss: 0.6256 - val_acc: 0.6630\n",
      "Epoch 22/30\n",
      "47000/47000 [==============================] - 37s 783us/step - loss: 0.5905 - acc: 0.6828 - val_loss: 0.5929 - val_acc: 0.6822\n",
      "Epoch 23/30\n",
      "47000/47000 [==============================] - 35s 749us/step - loss: 0.5783 - acc: 0.6920 - val_loss: 0.5943 - val_acc: 0.6830\n",
      "Epoch 24/30\n",
      "47000/47000 [==============================] - 36s 759us/step - loss: 0.5725 - acc: 0.6965 - val_loss: 0.5849 - val_acc: 0.6844\n",
      "Epoch 25/30\n",
      "47000/47000 [==============================] - 36s 764us/step - loss: 0.5653 - acc: 0.7023 - val_loss: 0.5807 - val_acc: 0.6931\n",
      "Epoch 26/30\n",
      "47000/47000 [==============================] - 36s 756us/step - loss: 0.5637 - acc: 0.7037 - val_loss: 0.5757 - val_acc: 0.6940\n",
      "Epoch 27/30\n",
      "47000/47000 [==============================] - 36s 758us/step - loss: 0.5582 - acc: 0.7055 - val_loss: 0.5731 - val_acc: 0.6938\n",
      "Epoch 28/30\n",
      "47000/47000 [==============================] - 36s 773us/step - loss: 0.5572 - acc: 0.7101 - val_loss: 0.5681 - val_acc: 0.6990\n",
      "Epoch 29/30\n",
      "47000/47000 [==============================] - 35s 749us/step - loss: 0.5496 - acc: 0.7139 - val_loss: 0.5668 - val_acc: 0.7070\n",
      "Epoch 30/30\n",
      "47000/47000 [==============================] - 35s 752us/step - loss: 0.5455 - acc: 0.7187 - val_loss: 0.5552 - val_acc: 0.7099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b0d288a90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Reshape\n",
    "model8ec = Sequential()\n",
    "model8ec.add(Conv2D(45, (5,5), input_shape=(X_tr.shape[1],X_tr.shape[2],X_tr.shape[3]), activation='relu', padding='same'))\n",
    "model8ec.add(Reshape((98,45)))\n",
    "model8ec.add(LSTM(100,input_shape=(98,45)))\n",
    "#model8ec.add(Bidirectional(LSTM(25)))\n",
    "model8ec.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "model8ec.add(Dense(100,activation='tanh'))\n",
    "model8ec.add(Dense(25,activation='tanh'))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "model8ec.add(Dense(10,activation='tanh'))\n",
    "model8ec.add(Dense(1, activation='sigmoid'))\n",
    "model8ec.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "display(model8ec.summary())\n",
    "model8ec.fit(X_tr, Y_train, validation_data=(X_te, Y_test), epochs=30,batch_size=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 7s 649us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.98729792147806"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8ec.evaluate(X_te, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 13s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.98729792147806"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model8ec.evaluate(X_te, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7304075 ],\n",
       "       [0.1507901 ],\n",
       "       [0.65374446],\n",
       "       ...,\n",
       "       [0.2640968 ],\n",
       "       [0.260233  ],\n",
       "       [0.37081453]], dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8ec.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model8ec.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10392, 1)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score, f1_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24793387191261895"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 1.0 - roc_auc_score(Y_test, k)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5383555351401011"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score=f1_score(Y_test,k.round())\n",
    "f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.72260802, 0.67201835]),\n",
       " array([0.86753126, 0.44904215]),\n",
       " array([0.78846559, 0.53835554]),\n",
       " array([6477, 3915]))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prfs=precision_recall_fscore_support(Y_test,k.round())\n",
    "prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7098729792147805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6634105606662408"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score_micro=f1_score(Y_test,k.round(),average='micro')\n",
    "f_score_macro=f1_score(Y_test,k.round(),average='macro')\n",
    "display(f_score_micro)\n",
    "f_score_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5619,  858],\n",
       "       [2157, 1758]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf=confusion_matrix(Y_test,k.round())\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.752066128087381,  Score/Loss : 0.24793387191261895, F1_Score_average: 0.5383555351401011, Precision, Recall, F1_score, Support: (array([0.72260802, 0.67201835]), array([0.86753126, 0.44904215]), array([0.78846559, 0.53835554]), array([6477, 3915]))\n",
      "F1_score_micro: 0.7098729792147805\n",
      "F1_score_macro: 0.6634105606662408\n",
      "Confusion Matrix\n",
      "[[5619  858]\n",
      " [2157 1758]]\n",
      "END\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC : \"+str(1.0 - score)+\",  Score/Loss : \"+str(score)+\", F1_Score_average: \"+str(f_score)+\", Precision, Recall, F1_score, Support: \"+str(prfs))\n",
    "print(\"F1_score_micro: \"+str(f_score_micro))\n",
    "print(\"F1_score_macro: \"+str(f_score_macro))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cf)\n",
    "print(\"END\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[1], tpr[1], _ = roc_curve(Y_test[:, 0], k[:, 0])\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.752066128087381}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd4FdXWwOHfSk/oJIhIb0LoaEQQBSwUARFBBUQs16vSRMAPEcFGsaCiIFUUuF5UrqIiCoKAIApSpUmRXhLpJYWQkLK/P+YkOQkph5CTyUnW+zx5Mn3WzCnrzN4ze4sxBqWUUiorXnYHoJRSqmDTRKGUUipbmiiUUkplSxOFUkqpbGmiUEoplS1NFEoppbKliaIQEJHeIvKz3XHYTUSqiEiMiHjn4z6riYgREZ/82qc7ichOEWmTi/UK7XtQRNqISLjdcdhJE0UeE5HDInLJ8YV1QkTmiEhxd+7TGPO5MaadO/dREDnO9T0p48aYo8aY4saYJDvjsosjYdW6lm0YY+obY1blsJ8rkmNRfQ8WFZoo3OM+Y0xxoAnQFBhhczy5Yuev5MLyC/1q6PlWBZUmCjcyxpwAlmIlDABExF9E3hORoyJyUkSmi0ig0/z7RWSriESJyAER6eCYXkpEPhWR4yISISJjU4pYROQJEfndMTxNRN5zjkNEvheRoY7hG0TkGxE5LSKHRGSQ03Kvi8h8EZkrIlHAExmPyRHHZ471j4jIKBHxcopjjYhMFpFIEdkjIndnWDe7Y1gjIh+IyFngdRGpKSK/iMhZETkjIp+LSGnH8v8FqgA/OK7eXsz4S1dEVonIGMd2o0XkZxEJcYrnMccxnBWRVzJeoWQ47kARed+xfKSI/O78ugG9Ha/pGREZ6bReMxH5Q0QuOI57soj4Oc03IjJARPYB+xzTJorIMcd7YLOI3OG0vLeIvOx4b0Q75lcWkdWORbY5zkcPx/KdHe+nCyKyVkQaOW3rsIgMF5HtwEUR8XE+B47YNzniOCkiExyrpuzrgmNfLZzfg45164vIMhE551j35SzOa5afB0ds651ez35iFY0FOMa/FuuqPVJEVotIfaftzhGRqSLykyPGNSJyvYh8KCLnHe/NphnOxQgR2eWYPztlP5nEnOVnqNAyxuhfHv4Bh4F7HMOVgB3ARKf5HwALgbJACeAH4C3HvGZAJNAWK4lXBOo65n0HzACKAdcBG4BnHfOeAH53DLcCjgHiGC8DXAJucGxzM/Aq4AfUAA4C7R3Lvg4kAF0dywZmcnyfAd87Yq8G7AWecoojERgC+AI9HMdT1sVjSASeA3yAQKCW41z4A+WwvqA+zOxcO8arAQbwcYyvAg4ANzq2twp42zGvHhAD3O44F+85jv2eLF7XKY71KwLewG2OuFL2OdOxj8ZAPBDqWO9moLnjmKoBu4HBTts1wDKs90OgY9qjQLBjnReAE0CAY94wrPdUHUAc+wt22lYtp203BU4Btzpiftxxzvydzt9WoLLTvlPPKfAH0McxXBxontl5zuQ9WAI47og9wDF+axbnNbvPg5fjNX8dqA2cB5o6rfsvxzr+wIfAVqd5c4AzjvMfAPwCHAIec5yLscDKDO+lvxznoiywBhjrmNcGCHeKKcvPUGH9sz2AwvbneMPFANGOD9MKoLRjngAXgZpOy7cADjmGZwAfZLLN8lhfPoFO03qlvNEzfEgFOAq0cow/DfziGL4VOJph2yOA2Y7h14HV2RybN3AZqOc07VlglVMc/+BIUo5pG4A+Lh7D0az27VimK7Alw7nOKVGMcprfH1jiGH4V+NJpXpDj2K5IFI4vh0tA40zmpeyzUoZj7pnFMQwGvnMaN8BdORz3+ZR9A38D92exXMZEMQ0Yk2GZv4HWTufvX5m8f1MSxWrgDSAki2POKlH0cn6dsjmubD8PTvs6h5VgR2SzrdKOmEo5xucAM53mPwfsdhpvCFzIcNx9ncY7Agccw21ISxTZfoYK65+WS7pHV2PMchFpDXwBhAAXsH4VBwGbRSRlWcH6Agbr18ziTLZXFesX+nGn9bywrhzSMcYYEZmH9WFdDTwCzHXazg0icsFpFW/gN6fxK7bpJMQRxxGnaUewfmWniDCOT4/T/BtcPIZ0+xaR8sBE4A6sX45eWF+aV+OE03As1i9jHDGl7s8YEytWkVdmQrB+lR642v2IyI3ABCAM67X3wfpF6izjcf8f8JQjRgOUdMQA1nskuzicVQUeF5HnnKb5Obab6b4zeAoYDewRkUPAG8aYH13Yr6sx5vR5wBhzWERWYn1xT0ldyCqyHAc85NhOsmNWCNZVLMBJp31dymQ8400mzuci5X2bkSufoUJH6yjcyBjzK9Yvm5Q6gzNYb9D6xpjSjr9Sxqr4BuuNWjOTTR3D+jUe4rReSWNM/UyWBfgSeFBEqmL9AvrGaTuHnLZR2hhTwhjT0TnsbA7pDFbxTFWnaVWACKfxiuL0qXfM/8fFY8i47zcd0xoaY0piFclINstfjeNYRYOAVQeBVdyTmTNAHJm/NjmZBuwBajuO4WXSHwM4HYejPuJF4GGgjDGmNNYXX8o6Wb1HMnMMGJfh9Q4yxnyZ2b4zMsbsM8b0wiomfAeYLyLFslvHab81XIgvp88DItIJ6ypjBfCu07qPAPcD9wClsK484MpzezUqOw2nvG8zcuUzVOhoonC/D4G2ItLYGJOMVZb9gYhcByAiFUWkvWPZT4EnReRuEfFyzKtrjDkO/Ay8LyIlHfNqOq5YrmCM2YL1IfwEWGqMSfn1swGIdlQSBjoqRhuIyC2uHIixbjv9ChgnIiUciWgoaVcsYH2pDBIRXxF5CAgFFl/tMTiUwCrGixSRiljl885O4toXUmbmA/eJyG1iVS6/ThZfMo7XbRYwwVGR6e2owPV3YT8lgCggRkTqAv1cWD4ROA34iMirWFcUKT4BxohIbbE0EpGUBJfxfMwE+orIrY5li4lIJxEp4ULciMijIlLOcfwp76FkR2zJZH3ufwQqiMhgR2V1CRG5NeNCOX0exLrx4BPg31j1K/eJSMoXcgmsHx5nsa5K3nTlmHIwQEQqiUhZYCTwv0yWuabPkKfSROFmxpjTWBXArzomDQf2A+vEurNoOVbFJMaYDcCTWBV8kcCvpP16fwyr2GAXVvHLfKBCNrv+AuvX1hdOsSQBnbHuwjpEWjIpdRWH9BxWufJB4HfH9mc5zV+PVfF4Bqto4EFjTEqRztUewxvATVjnYhHwbYb5bwGjxLqj5/+u4hgwxux0HMs8rKuLGKyK3/gsVvk/rErkjVhl5u/g2ufn/7B+/UZjfSlm9uXjbCmwBOsmgSNYVzLORSITsJL1z1gJ6FOsSnSwkt1/HOfjYWPMJqw6qslY53s/mdzJlo0OwE4RicEqAuxpjLlkjInFem3XOPbV3HklY0w01k0I92EVye0D7sxiH1l+HoCPge+NMYsd76GngE8cifEzx/mJwHo/rbuK48rKF1jn9SBW0dnYjAvk0WfI46TcGaPUNRORJ4B/G2NutzuWqyXWQ5EXsIqIDtkdj8pfInIY67273O5YCiK9olBFlojcJyJBjnL397CuGA7bG5VSBY8mClWU3Y9VYfkPVnFZT6OX2EpdQYuelFJKZUuvKJRSSmXL4x64CwkJMdWqVbM7DKWU8iibN28+Y4wpl5t1PS5RVKtWjU2bNtkdhlJKeRQROZLzUpnToiellFLZ0kShlFIqW5oolFJKZUsThVJKqWxpolBKKZUtTRRKKaWy5bZEISKzROSUiPyVxXwRkUkisl9EtovITe6KRSmlVO658zmKOVjNG3+Wxfx7sdrXqY3Vuc40x3+llFLOLp2D+PNgkq/8izoMXtl/lV++nJzt/Jy4LVEYY1aLSLVsFrkf+MzRCNs6ESktIhUcHdwopVThlxgHKwdDcgIkJzr9JcA/a8G3GEQevKZdDPuhLVv+ya7bl5zZ+WR2RdJ3yBLumHZFohCRZ4BnAKpUqZIvwSmlVJ66HA1/zYKEWDjzF5z6E87tubptlK4F4mX9Idb/xFi4HAPlb850lQYNQ5i0pto1he4RTXgYYz7G6u2KsLAwbe5WKVUwGQPH18H+BRB3HpLi4NASuHQ6+/Wqd4Q6D1tFSOJj/ffyBZMIJatBcD3wCXAphF27TvPnn8d59NFGADzWzdD6hUiqVx+d68OyM1FEkL4z80qOaUopVTAlXISLJ+HkJuvK4NhK6ws9KQ52f+7aNm5oCVXbWsMVb4fKrXOsY3BFbGwCY8eu5t131+LtLTRvXolatcoiIlSrVvqatm1nolgIDBSReViV2JFaP6GUKhCSEiA+0koAcefgp8fg9Lar20b5MGjwJASGQFI8VGoNgeXANzDnda/STz/tY8CAxRw6dAGAp566meDgvNuP2xKFiHwJtAFCRCQceA3wBTDGTAcWAx2xOlaPBZ50VyxKKZWOMRDzj/UFnhQPCTFw6SwkXYYNb8Lx9dmv7+0P1zWBck3ArwSUawTeASBiFSP5BuXLYURERDF48FLmz98FQKNG5Zk+vRMtWlTOYc2r4867nnrlMN8AA9y1f6WUSmUMRIfDly0g7qx1t5Erit8APoFw4QBcfwv0XAPevu6N9SoMGLCY77//m6AgX0aPbsPzzzfHxyfvH4/ziMpspZRySWIchP8Gf8+Dw0vAJwgu7M96+eKVrFtQffwh6iiENIRiFazipq7f59uVwdVITExOTQbvvHMPvr7evP9+O6pUKeW2fWqiUEp5HmOs4qKLJ2Hz+7BtunVXkCtXCuXD4KEVVpGRiPtjzSORkXGMGvULe/eeY8mS3ogIdeqE8PXXD7l935oolFKeI/YULOoFR3+5cl7GJNFqPJSpA6WqQenaViLxoMSQwhjD11/vYvDgJRw/HoO3t7B16wmaNr22h+iuhiYKpVTBlZRgPZj22wjrVtSMAoIhIRqqtofmo+D6MMfDaIXDgQPnGDjwJ5YssYrPWrSoxPTpnWnUqHy+xqGJQillP5MM//wB26bB6e3W3Ufn/856+TJ14P4FEFw3/2LMZ++9t5ZXXllJXFwipUsH8M479/Dvf9+El1f+XxVpolBK5b/4KCshnNoMx36F/d/lvE6N++CeaVCiovvjKwBiYxOIi0ukT59GvPdeO667rphtsWiiUEq517m/rYbt/llrtUm0bZr17EJm/EtD+Zug9fvWsH8pCCiTv/Ha5PTpi/z991luv91qz2748Ja0aVONVq2q2hyZJgqlVF4yxmro7q/ZcGoLHF2e/fKV20BMBNz4MDR6Gkra/6WY35KTDbNmbeHFF5fh4+PFnj0DKVs2EH9/nwKRJEAThVIqL5zcDHu/gQ1vZb1MzS7W8wn1+oBfKasRPA+8Cykv/fXXKfr2/ZE1a6yGtNu2rUFsbAJly+Z9Mx/XQhOFUir3zv0N37SHqCPppweUBZMEYcOg1v0Q0sCe+AqoixcvM3r0r0yYsI7ExGTKly/Ghx92oEeP+kgBTJ6aKJRSrju7B/5ZAyv6g29x6wrBWfV7oeWYLPtGUJYHH/yaJUv2IwL9+4cxbtzdlC7tWjPidtBEoZTKmjEQfwFWD4cdM9PPS3JKErW6QqcvXe4zoagbPrwlJ0/GMG1aJ269tZLd4eRIE4VSKr3kJNj3jdXhzs7ZmS9T836rjqHWA25pNrswSUxM5qOP1nP48AUmTrwXgDZtqrFp0zO2PBORG5oolFJp/pxo9eGcUWAIXDoD/U5BULn8j8tDbdgQwbPP/sjWrScAeOaZm6lf/zoAj0kSoIlCKZWUAH//D37qc+W8Rs/CTYOsrjiVyy5ciOPll1cwffomjIGqVUsxeXLH1CThaTRRKFVUHV8Pv4+EoyuunNfvJAR55pea3ebN+4vBg5dw8uRFfHy8eOGFFrzySiuKFfOzO7Rc00ShVFGScNG6pXVuJnclFbsemr0MTQcW+ecbrsXPPx/g5MmLtGxZmWnTOtGwYf424OcOmiiUKip2fw6LH71yerOX4NaXrf4Z1FWLj08kIiKaGjWspkbGj2/LHXdU4fHHm3hUPUR2NFEoVVid2Ahbp1rNbifEWr2+pQgItuoeWrxqX3yFwC+/HKJfv0V4eQnbtvXFz8+bkJAgnnyyqd2h5SlNFEoVBsZYDe9dOGg1updda6z9z0BgcP7FVgidPBnD//3fMubO3Q5A3bohhIdHpV5VFDaaKJTyVBdPwm/D4cgKiAnPerlbR0JwKPgEQqXWmiSuQXKyYebMzbz00gouXIgjIMCHUaPuYNiwlvj5edsdnttoolDK0yRcgr1fw5LHM59frYP13MOdEyGwbP7GVsg98MD/WLjQ6lCpffuaTJnSkZo1C/851kShlCeIWAM758COT66cV7oW3DIM6j0OPv75HlpR0q1bXTZsiGDixA489FC9AtmAnztoolCqoIo5bjXbfXgJnN+X+TJdf4CanfM3riJk4cK/CQ+Pon//WwB47LHGdOsWSokSRSsha6JQqqCJjrCec4g9eeW8Nh9A+TCodHv+x1WEHD0ayaBBP/H993/j7+9Nhw61qFGjDCJS5JIEaKJQyn5x52HtaxDzj9UYX0Ytx1rNdle9B7z0I+tOCQlJTJq0ntdeW8XFiwmUKOHH2LF3UbVqKbtDs5W+65SyU9RRmJlFd5chDeCRdeBbLH9jKqLWrQvn2Wd/ZPt260ruoYfq8cEH7alYsaTNkdlPE4VS+eVyDOz8j3XH0qUzcPF4+o5/rrsJwoZClXugmOc3++BpXnllJdu3n6R69dJMntyRjh1r2x1SgaGJQil3MQbO77USw8k/M38IzsvH6v+h2XC4I5v+plWeM8YQHX2ZkiWtOofJk+/ls8+2MXJkK4KCfG2OrmDRRKFUXouPghUDYPfczOfX7gaN+0Op6tbzDv5atJHf/v77DP37L0YEli3rg4hQp04I48bdbXdoBZImCqWuVdx5WDfGaq779PYr53v7Q9W2Vm9wVdtCycr5H6MCIC4ukbfe+o23317D5ctJBAcHcvjwBapXL5xNb+QVTRRKXYvIw/BJ9cznla4JvdZqvw4FxLJlB+jffzH791v1Qv/6VxPGj29LcHCQzZEVfG5NFCLSAZgIeAOfGGPezjC/CvAfoLRjmZeMMYvdGZNSeWLLZPjlufTTqrW32lJq+DQEhdgTl7qCMYannlrI7NlbAahXrxzTp3fijjuyuNtMXcFtiUJEvIEpQFsgHNgoIguNMbucFhsFfGWMmSYi9YDFQDV3xaTUNYlYCxvehIOLrpzXfYmVKFSBIyJUq1aawEAfXn21NUOHtijUDfi5gzuvKJoB+40xBwFEZB5wP+CcKAyQUpNXCvjHjfEo5ZqY4xD+K8REwMUTcGQ5nN6a+bIPrYDKbaw+H1SBsXXrCY4fj+bee61bXIcPb0mfPo20LiKX3JkoKgLHnMbDgVszLPM68LOIPAcUA+7JbEMi8gzwDECVKlXyPFBVxCXGWY3tXTwO69/Mefn6T0DjflChmdtDU1cnOjqe115bxcSJ6wkODmTPnoGULRuIv7+PJolrYHdldi9gjjHmfRFpAfxXRBoYY5KdFzLGfAx8DBAWFmZsiFMVVkv/DX99mvm80rXg+mYQUMZ6JiJsqFVBrQocYwwLFuxh0KAlhIdH4eUlPPJIQ3x99UovL7gzUUQAzvcBVnJMc/YU0AHAGPOHiAQAIcApN8alFJz7G2bXTT+tfBjU7g61ukJw3czXUwXOkSMXGDjwJ378cS8AYWE3MGNGZ266qYLNkRUe7kwUG4HaIlIdK0H0BB7JsMxR4G5gjoiEAgHAaTfGpIq6qGMwM5PiywHnrCsH5VGMMXTv/hWbNx+nZEl/3nzzLvr2DcPbW68k8pLbEoUxJlFEBgJLsW59nWWM2Skio4FNxpiFwAvATBEZglWx/YQxRouWVN478xf8p+GV0299GVqO0cpoD5OcbPDyEkSE995rx/Tpm/jgg/ZUqFDC7tAKJfG07+WwsDCzadMmu8NQnuLYKvhzIuxfkH5681eh5Ru2hKRy7+zZWF56aTkAM2d2sTkazyIim40xYblZ1+7KbKXyljGw7Bk4vs66isiow3+gbk/w9sv/2FSuGWP47LNt/N//LePMmVj8/Lx57bU2VKqk7WTlB00UqnC4dBYW9YIjyzKff9dkqNNDn5j2QLt3n6Zfv0X8+usRANq0qca0aZ00SeQjTRTKM5lk2L8Qzv4Fa165cr5vMej4OVS5C/y03NoTGWN49dWVvPPOGhISkgkJCeL999vRp08jRMTu8IoUTRTK8xgDE7JogqH1+9D0OfDW/gQ8nYgQERFNQkIyTz99E2+/fQ9lywbaHVaRpIlCeY5TW+HHh+H8vvTTbx8H8ZHQ/BXwK25PbCpP/PNPNGfOxNKokdXD3/jxbXnqqaa0bKktMthJE4Uq+Na+AZsnwOWo9NNrd4Mu39gTk8pTSUnJTJu2iZEjf6FixRJs3doXPz9vQkKCCAnRJGE3TRSqYPukJkQeTD/t1pFw02CtmC4k/vzzOM8++yObNlltgrZqVZWoqHhCQrSfiILCpUQhIn5AFWPMfjfHo5RVB3FmByzunT5J9FoLFW7Vh+MKiaioeF555RcmT95IcrKhUqWSTJrUga5d62pldQGTY6IQkU7ABMAPqC4iTYDXjDEPuDs4VcREHYM/3si8kb6hyaBfHoWGMYZWrWazbdtJvL2FoUOb8/rrbShRwt/u0FQmXLmiGI3VPPhKAGPMVhGp5daoVNETsRbmtUw/Leg6qHwndJyrSaKQERGGDGnO1KmbmDGjM02aXG93SCobriSKBGPMhQyXgp7V7ocq2LbNgOV908ZrdIJ750JAaftiUnnq8uUkJkz4A29vYdgw6wfBY4815tFHG2kDfh7AlUSxW0QeBrwcLcEOAta5NyxVJJzdA8uehojf06b1XAMVb7MvJpXnfvvtCH37LmLXrtP4+3vz2GONKV++OCKCt7deKXoCVxLFQOBVIBn4Fqs12JfdGZQq5JISrJZcz/+dfnr/MxAYbE9MKs+dORPLiy8uY/ZsqxvZ2rXLMnVqJ8qX12ddPI0riaK9MWY4MDxlgoh0w0oaSl2dfQtgYYb7IFqOgSYDtaipkDDGMGfOVoYNW8bZs5fw8/NmxIjbeeml2wkI0DvyPZErr9oorkwKIzOZplTWEi7C9ApwOTptWtlQeGKnVlQXQnPn7uDs2UvcdVd1pk7tSJ06+syLJ8syUYhIe6xuSiuKyASnWSWxiqGUylnCJTi0CH54KP30Hquh0h32xKTyXGxsApGRcVSoUAIRYerUjmzc+A+9ezfUZyIKgeyuKE4BfwFxwE6n6dHAS+4MShUCUUfh01qQnJB+eoXm0GuNPjRXiPz00z4GDFhMjRplWLasDyJCnTohehVRiGSZKIwxW4AtIvK5MSYuH2NSnsoYiD0Fa1+D7TOunN97A1x/S/7HpdwiIiKKwYOXMn/+LgBKlPDn7NlL2vRGIeRKHUVFERkH1AMCUiYaY250W1TK85zcAl+1ubLhvltehFbv2BKSco+kpGSmTNnIqFG/EB19mWLFfBk9+k4GDboVHx+9UiyMXEkUc4CxwHvAvcCT6AN3KsXRX2DdWDi2Mm1amTpQ8z64423wyqLfCOWRkpMNrVvPYc2aYwB07VqXiRM7UKVKKZsjU+7kSqIIMsYsFZH3jDEHgFEisgnIpFsxVaS8n0klZY9foVKr/I9F5QsvL6Fdu5ocPRrJ5Mkd6dKljt0hqXzgSqKIFxEv4ICI9AUiAO1bsig7tAS+vTf9tDYToOG/tdvRQsYYw1df7cTHx4vu3esBMHx4S4YObUHx4n42R6fyiyuJYghQDKvpjnFAKeBf7gxKFWCnd1yZJF7QksjC6MCBc/Tvv5iffz5AuXJB3HVXdcqUCcTf3wd/beS1SMkxURhj1jsGo4E+ACJS0Z1BqQLq+Hr4onnaeKcvoU4P++JRbhEfn8i7765l3LjfiItLpEyZAMaNu4tSpQJyXlkVStkmChG5BagI/G6MOSMi9bGa8rgLqJQP8amC4tS29Emi5+9QsWXWyyuPtGrVYfr1W8SePWcA6NOnEe+9147rritmc2TKTlneyyYibwGfA72BJSLyOlafFNsAvTW2KNk2Hf7bJG28x2pNEoVQUlIy/ftbSaJOnWB++eUxPvvsAU0SKtsrivuBxsaYSyJSFjgGNDTGHMxmHVXY7PwMlvdLG287Q5veKESSkw1xcYkEBfni7e3FtGmdWL36CC++2BJ/f23AT1myeyfEGWMuARhjzonIXk0SRczlaFjyeNr4EzshuJ598ag8tWPHSfr2XUTdusF8+un9ALRuXY3WravZG5gqcLJLFDVEJKWFWMHqLzu1xVhjTDe3RqbsdeYvq8+IFE8dgNI17ItH5ZmLFy8zevSvTJiwjsTEZA4dOs/585coUybQ7tBUAZVdouieYXyyOwNRBcifE2Hl4LTxxn01SRQSP/zwNwMH/sTRo5GIQP/+YYwbdzelS+sdTSpr2TUKuCI/A1EFwKltVt/Vx516ur3zQ2g6yL6YVJ5ITEymR4/5fPvtbgCaNLmeGTM606yZ3umucqa1VcryWWM4vT39tAHntde5QsLHx4tSpfwpXtyPMWPuZODAZtqAn3KZW98pItJBRP4Wkf0ikmkfFiLysIjsEpGdIvKFO+NRmTjwI3zRIn2SaDkGBsVqkvBw69eHs359eOr4u++2ZffuAQwe3FyThLoqLl9RiIi/MSb+Kpb3BqYAbYFwYKOILDTG7HJapjYwAmhpjDkvIte5Hrq6ZvPbw5Gf00/T5jg83oULcYwYsZwZMzZTt24IW7f2xc/Pm+Bg7SdC5U6OPytEpJmI7AD2OcYbi8hHLmy7GbDfGHPQGHMZmIf1bIazp4EpxpjzAMaYU1cVvcq98N/SJ4lW78Kgi/bFo66ZMYYvvthB3bqTmT59M97eXnTpUoekJO25WF0bV64oJgGdgQUAxphtInKnC+tVxHpIL0U4cGuGZW4EEJE1gDfwujFmiQvbVtfqf05NgQ9NBu3X2KPt23eW/v0Xs3y59ahTy5aVmT69Mw0a6EW6unauJAovY8yRDB2kJ+Xh/msDbbDajlotIg1LWSZYAAAgAElEQVSNMRecFxKRZ4BnAKpUqZJHuy6ijIGZ1dLGe67RJOHhEhKSuOuuzwgPj6Js2UDGj7+HJ59sipeXvq4qb7iSKI6JSDPAOOodngP2urBeBFDZabySY5qzcGC9MSYBOCQie7ESx0bnhYwxHwMfA4SFhWkhem5djoaPK0N8pDV+40NQ8TZ7Y1K5ZoxBRPD19WbcuLtYufIw48ffQ7ly2jaTyluu3PrQDxgKVAFOAs0d03KyEagtItVFxA/oCSzMsMwCrKsJRCQEqyhKmwlxh8hD8FHJtCQRXA86/8/emFSunDwZQ58+3zF27OrUaY891pjZs+/XJKHcwpUrikRjTM+r3bAxJlFEBgJLseofZhljdorIaGCTMWahY147EdmFVZw1zBhz9mr3pXJw4EdYcF/aeLtPoOFT9sWjciU52TBz5mZeemkFFy7EUbp0AIMHN6dECe1FSLmXGJN9SY6IHAD+Bv4HfGuMic6PwLISFhZmNm3aZGcIniHhEuz7BlYOgrjzadPvmw83ZmydRRV027adoG/fRaxbZz0X0aFDLaZM6UiNGmVsjkx5ChHZbIwJy826rvRwV1NEbsMqOnpDRLYC84wx83KzQ5UPzu6BOaFXTv/3QShVPf/jUbmWkJDEiBEr+PDDdSQlGSpUKM7EiR148MF6iN6EoPKJS49nGmPWGmMGATcBUVgdGqmC6MTG9EkioAzcOdG6BVaThMfx8fFiy5YTJCcbnnuuGbt3D+Chh+prklD5KscrChEpjvWgXE8gFPge0FtlCpqINTDv9vTTHl4JldvYEo7KvaNHI0lKSqZ69TKICNOndyIyMp6wsBvsDk0VUa5UZv8F/ACMN8b85uZ41NVKjIPvH4DDTs8pBpW36iIq3Z71eqrASUhIYuLE9bz22ipatKjEsmV9EBFq1w62OzRVxLmSKGoYY7QNgILo8FL4pkP6aV1/gJqd7YlH5doffxyjb99FbN9+EoCyZQOJjU2gWDE/myNTKptEISLvG2NeAL4RkStujdIe7mz028uw4a300xr8C9p+DF7e9sSkcuX8+Uu89NJyPv74TwCqVy/NlCkduffe2jZHplSa7K4oUp7G0p7tCorvH4D9C9JPK1kVunwL5W+yJyaVa/HxiTRpMoOjRyPx9fVi2LDbGDmyFUFBvnaHplQ62fVwt8ExGGqMSZcsHA/SaQ94+SUhFiZl8sTtv/ZCGf3l6an8/X146qmmrFhxiGnTOlGvXjm7Q1IqU648cPenMeamDNO2GGOaujWyLBSpB+6SLsPC7nDwx7Rp3v7w9BEoVt6+uFSuxMUl8tZbv1GnTgiPPNIQsLoo9fYWvd1VuZ1bHrgTkR5Yt8RWF5FvnWaVAC5kvpbKM8bA583g9La0ac1fgZaj7YtJ5dqyZQfo338x+/ef47rrivHAA3UJDPTVnuaUR8iujmIDcBar1dcpTtOjgS3uDEoBWyalJYnmr0LzUeCtZdee5sSJGIYOXcqXX/4FQP365Zg+vTOBgfpaKs+RXR3FIeAQsDz/wlEA7PsOVg62hjt+AaG97I1HXbWkpGRmzNjMyy+vIDIynsBAH157rTVDhrTAz0/vTFOeJbuip1+NMa1F5DzgXJEhgDHGlHV7dEXR5g9g1dC0cU0SHikpyfDRRxuIjIynY8faTJ58L9WrawN+yjNlV/SU0t1pSH4EooBfnreKnFI8m7GfJ1WQRUfHk5RkKF06AD8/b2bOvI+TJ2Po1i1UK6uVR8uyJs3paezKgLcxJgloATwLaO8oeS18dfokMeAcFNe2fTyBMYZvv91NaOgUXnhhaer022+vQvfu2sqr8nyu3HKxAKsb1JrAbKyuSr9wa1RFzc7/wP9ap433O221+qoKvMOHL9Clyzy6d/+KiIho/vrrNHFxiXaHpVSeciVRJDv6tO4GfGSMGQJUdG9YRciR5bDkibTxx3dAkJb2FXQJCUm8887v1Ks3hR9/3EvJkv5Mnnwva9f+i4AAV5pQU8pzuNQVqog8BPQBujqm6b19ecEYmN82bfzZf6B4BfviUS6JjU2gefNP2LHjFAA9ezZgwoR2VKhQwubIlHIPVxLFv4D+WM2MHxSR6sCX7g2rCDi+Ab64NW28zQRNEh4iKMiXsLAbiI1NYOrUTrRrV9PukJRyqxyb8AAQER+glmN0vzHGtkJYj2/CwxiruOmbdmnTgspbdzhpy68FkjGGzz7bRs2aZbn99ioAREbG4efnrQ/OKY/h1j6zReQO4L9ABNYzFNeLSB9jzJrc7LBIS4yDiYHpp3X7Cap3yHx5Zbvdu0/Tr98ifv31CKGhIWzd2hc/P29KlQqwOzSl8o0rRU8fAB2NMbsARCQUK3HkKjMVWQkXYVLxtPEyta3mwUMa2BeTytKlSwmMG/cb48evISEhmXLlghgx4nZ8fbVtJlX0uJIo/FKSBIAxZreIaLdbV+P3UbB+XNr4zUOsOglVIC1Zsp8BAxZz8OB5AJ5++ibefvseypYNzGFNpQonVxLFnyIyHZjrGO+NNgrouvjI9Enijreh2XD74lHZiom5TJ8+33HmTCwNGlzH9OmdaNmyit1hKWUrVxJFX2AQ8KJj/DfgI7dFVJgkJ8HHTl8yA85DQGn74lGZSkpKJjnZ4OvrTfHifkyc2IHw8CiGDGmOr6/eYKBUtolCRBoCNYHvjDHj8yekQuL0DvisUdp4/Sc1SRRAmzf/w7PP/sj999fhlVesp+NTOhVSSlmyrJkTkZexmu/oDSwTkX/lW1SeLO4CLO+fPknUfQTaf2pfTOoKUVHxPP/8TzRr9gmbNx/nv//dTkJCkt1hKVUgZXdF0RtoZIy5KCLlgMXArPwJy0PFnYcpGVpf7/UH3NDcnnjUFYwxzJ+/i+efX8Lx4zF4ewtDhzbnjTfu1GImpbKQXaKIN8ZcBDDGnBYRvS8wO/GR6ZNE5TvhgUXgq3fKFBTR0fH06DGfn37aD8Ctt1Zk+vTONGlyvc2RKVWwZZcoajj1lS1ATee+s40x3dwamaeZHZo2fM80aNzXvlhUpooX9yM+PolSpfx5++17eOaZm/Hy0ibAlcpJdomie4bxye4MxKOd3w8Xj1vD1dprkihAVq8+QoUKxaldOxgRYdasLgQE+FC+fPGcV1ZKAdn3mb0iPwPxWMdWwVd3po3fv8C2UFSaM2diefHFZcyevZW7767OsmV9EBGqVtU7z5S6Wtpw/rU4uhK+vittvOUY8NE2gOyUnGyYM2crw4Yt49y5S/j5eXPHHVVISjL4+Ggxk1K54dZEISIdgImAN/CJMebtLJbrDswHbjHGeEbTsPu+hYVOpXMPr4LKrbNcXLnfzp2n6NdvEb/9dhSAu++uztSpnbjxxmCbI1PKs7mcKETE3xgTfxXLewNTgLZAOLBRRBY6txvlWK4E8Dyw3tVt2+7iyfRJosdvUOl2++JRREbG0bz5p8TEXOa664oxYUI7HnmkofZXrVQeyPGWVxFpJiI7gH2O8cYi4koTHs2w+q44aIy5DMwD7s9kuTHAO0Cc62Hb6MIBmO50O2XvjZokbJTSn0qpUgEMH96Svn1vZs+eAfTu3UiThFJ5xJVnIyYBnYGzAMaYbcCd2a5hqQgccxoPJ0Nf2yJyE1DZGLMouw2JyDMisklENp0+fdqFXbvRH6PThjt+Dtdra+t2iIiI4sEHv2Lu3O2p00aOvINp0zpTpow+u6JUXnIlUXgZY45kmHbNbR04HuCbALyQ07LGmI+NMWHGmLBy5cpd665z7+xu2PWZNdzwaQh9xL5YiqjExGQmTlxH3bpT+Oab3bz22iqSkpIB9ApCKTdxpY7imIg0A4yj3uE5YK8L60UAlZ3GKzmmpSgBNABWOT7g1wMLRaRLgavQzqxpjrq97ImlCNu4MYK+fRfx55/WMytdu9Zl0qQOeHtrowFKuZMriaIfVvFTFeAksNwxLScbgdoiUh0rQfQEUn+CG2MigZCUcRFZBfxfgUsSJvnKJHHPNKjiSumbygsXL15m+PDlTJ26EWOgSpVSfPTRvXTpUsfu0JQqEnJMFMaYU1hf8lfFGJMoIgOBpVi3x84yxuwUkdHAJmPMwquO1g4TnBqKu/EhuO8r+2Iponx8vFi+/CBeXsLQoS147bXWFCumnSwqlV9yTBQiMhMwGacbY57JaV1jzGKsVmedp72axbJtctpevkqMh/Vj08a9fKHz/+yLp4g5cOAcpUsHEBwchL+/D//97wMEBPjQsGF5u0NTqshxpehpudNwAPAA6e9mKnzio2ByqfTThly2J5YiJj4+kXffXcu4cb/Ru3dDPvmkCwC33FIxhzWVUu7iStFTup/RIvJf4He3RWQ3Y9IniRtawl2T7IunCFm16jD9+i1iz54zgHWHU1JSslZWK2Wz3DThUR0ovNf/y53q6es/Dh3m2BZKUXHq1EWGDVvGZ59tA6BOnWCmTevEnXdWtzkypRS4VkdxnrQ6Ci/gHPCSO4OyTdx52D4jbVyThNudORNLaOgUzp27hL+/NyNH3sGLL7bE31/bq1SqoMj20yjWAw6NSXv+IdmktJlQ2MRdSH8b7IBz9sVShISEBHH//XUID49i6tRO1KpVNueVlFL5KttEYYwxIrLYGNMgvwKyzZQyacN3TYaAMlkvq3Lt4sXLjB79K5063UirVlUBmDq1E/7+3vpktVIFlCu1hFtFpKnbI7HT+05fUMUqQNMB9sVSiP3ww9/UqzeV8ePX0r//IpKTrYvTgAAfTRJKFWBZXlGIiI8xJhFoitVE+AHgIlb/2cYYc1M+xehe26anDQeVh6cO2BdLIXXsWCTPP7+E777bA0DTptczY0Zn7a9aKQ+RXdHTBuAmoEs+xZL/kpPS3+XU74R9sRRCiYnJTJq0nldfXcnFiwkUL+7H2LF3MmBAM3x89JZXpTxFdolCAIwxhfMntkmGD5wOv/sS+2IppKKi4nnrrd+5eDGB7t1D+fDDDlSqVNLusJRSVym7RFFORIZmNdMYM8EN8eQPY9K34RTSAKq1ty+eQuTChTgCA33w9/ehbNlAZszojL+/N5063Wh3aEqpXMru+t8bKI7VHHhmf57rb6eHzWt0hsd32BdLIWGM4YsvdlCnzmTGj1+TOr1bt1BNEkp5uOyuKI4bY0ZnM98znd4Oixx9SZSqAQ/8YG88hcDevWfp338RK1YcAmD16qMYY/ROJqUKieyuKArfp3zNa/BZ47TxZoXzAfP8EheXyBtvrKJhw2msWHGIsmUD+fTTLixd+qgmCaUKkeyuKO7OtyjyQ3ISrHO6QGrcFxo9bV88Hu7EiRhatZrNvn3WE+xPPNGEd99tS0hIkM2RKaXyWpaJwhhTuNqwiI9MGx58Gbx97YulEChfvhiVK5fCx8eLadM60bp1NbtDUkq5SdFpee2w4/ZXnwBNErmQnGyYOXMzd95ZnRtvDEZE+OKLbpQpE4ifn3fOG1BKeayi8dSTMbC4tzXsp/fxX61t207QsuUs+vZdRP/+i0hpF7J8+eKaJJQqAorGFcWntdKGG/e3Lw4PExNzmddfX8WHH64jKclwww0l6Ns3zO6wlFL5rPAnivP7IfJg2vhtr9kXiwdZsGAPzz33E+HhUXh5Cc8914yxY++iZEl/u0NTSuWzwp8onNtyGppkXxweJCIiip495xMfn8TNN1dg+vTOhIXdYHdYSimbFO5EYQwcXW4Nhw0DKRpVMrmRkJCEj48XIkLFiiUZN+4u/Py86d//Fu2zWqkirnB/A2ydkjYc9oJ9cRRwa9ce4+abP2bu3O2p01544Taee+5WTRJKqUKcKEwy/PJc2nix8vbFUkCdO3eJZ5/9gZYtZ7FjxymmTt1EYe3pVimVe4W36GnNK2nDD/1iXxwFkDGGuXO388ILP3P6dCy+vl68+GJLRo68Q5veUEpdofAlioSLMKl4+mlV7rQnlgLo5MkYevX6hpUrDwPQunVVpk3rRGhoOXsDU0oVWIUvUSx6JP34Y9vsiaOAKl06gOPHYwgJCeK999ry2GON9SpCKZWtwpUoDvwIBxZaw6GPQsf/2htPAbFs2QFuuqkCwcFB+Pv78PXXD1GhQnGCg7UBP6VUzgpPZbYxsOC+tPF2n9gXSwFx/Hg0vXp9Q7t2cxk+fHnq9AYNrtMkoZRyWeG5otj7ddpw96XgU3SfIE5KSmbGjM2MGLGCqKh4AgN9qFMnWDsTUkrlSuFJFFunWv/FG6q1szcWG/3553H69v2RjRv/AaBTp9pMntyRatVK2xyZUspTFY5EkXARwn+1hpsNtzcWGx0+fIFmzWaSlGSoWLEEkybdywMP1NWrCKXUNXFrohCRDsBEwBv4xBjzdob5Q4F/A4nAaeBfxpgjV72jje+mDd80OPcBe7hq1Urz5JNNKFHCnzfeaEOJEkW3+E0plXfcVpktIt7AFOBeoB7QS0TqZVhsCxBmjGkEzAfGX/WOjiyHP96whoPrQ1DReR7g8OEL3Hffl/z66+HUaR9/fB8TJrTXJKGUyjPuvKJoBuw3xhwEEJF5wP3ArpQFjDErnZZfBzx6VXswyTC/bdp4py9zH60HSUhIYsKEP3jjjV+5dCmRM2di+eOPpwC0mEkplefcmSgqAsecxsOBW7NZ/ingp8xmiMgzwDMAVapUSZsx68a04T5boVzD3MbqMX7//Sh9+/7Izp2nAejZswETJhTdynullPsViMpsEXkUCANaZzbfGPMx8DFAWFiYcUyECwfSFrqusbvDtNX585cYNmwZn366BYCaNcswdWon2rWraXNkSqnCzp2JIgKo7DReyTEtHRG5BxgJtDbGxLu89fN704YHxeQ2Ro+RnGz4/vu/8fX14qWXbmfEiNsJDPS1OyylVBHgzkSxEagtItWxEkRPIF1DTCLSFJgBdDDGnLqqrYevtv4HlAHfYnkQbsGzZ88Zqlcvjb+/D8HBQXz+eTeqVClF3bohdoemlCpC3HbXkzEmERgILAV2A18ZY3aKyGgR6eJY7F2gOPC1iGwVkYUu7+CUVQRDcP28DLtAiI1NYOTIFTRqNI3x49ekTm/XrqYmCaVUvnNrHYUxZjGwOMO0V52G78n1xnfPtf5XyrRaw2MtWbKf/v0XcejQBQDOnIm1OSKlVFFXICqzc8WvFFyOhtBHcl7WA/zzTzSDBy/h66+tu4cbNryO6dM7c9ttlXNYUyml3MtzE0VygvXfv4y9ceSBvXvPEhb2MdHRlwkK8uX111szeHBzfH297Q5NKaU8NFEYA7EnrWEvz7/zp3btstxyS0WKFfPlo4/upWpVbcBPKVVweGaiSHl+wtsPAoPtjSUXoqLiefXVlfTvfws33hiMiLBwYU+KFfOzOzSllLqCZyaKlKuJpMvgQU1WGGOYP38Xzz+/hOPHY9iz5wxLllitlmiSUEoVVJ6ZKE5utv5Xv9feOK7CwYPnGThwMT/9tB+A5s0r8c47ub/pSyml8otnJorES9b/JNcf5LbL5ctJvPfeWsaMWU1cXCKlSwfw9tt38/TTN+Pl5TlXQ0qposuzE8UNt9sbhwuOHYtk9OhfiY9Ponfvhrz/fjvKly9ud1hKKeUyz0wU+76x/vsE2BtHFs6fv0Tp0gGICDVrlmXixA7UqlWWu++uYXdoSil11dzWhIdbnfnL+m+S7I0jg+Rkw6xZW6hV6yPmzt2eOv3ZZ8M0SSilPJbnJQrneon6T9oXRwY7d56iTZs5PPXUQs6du5Raaa2UUp7O84qeEpzaPipR0b44HGJjExgz5lfee+8PEhOTue66YnzwQXt69Wpgd2hKKZUnPC9RXI60/lfrYG8cWE1vtG8/l8OHLyACffvezJtv3k2ZMoF2h6aUUnnG8xJFcqL1v0Qle+MAqlYtRUCAD40bl2f69M40b25/TKrgSEhIIDw8nLi4OLtDUUVIQEAAlSpVwtc375o38rxEYayeUKma//1EJyYmM336Jnr1akBwcBD+/j4sWdKbihVL4uPjedU9yr3Cw8MpUaIE1apVQzyoBQHluYwxnD17lvDwcKpXr55n2/W8b7eEaOu/f/42nLdhQwTNms3kued+Yvjw5anTq1YtrUlCZSouLo7g4GBNEirfiAjBwcF5fhXreVcUCGCgTK182VtkZBwjR/7C1KkbMQaqVCnF/ffXyZd9K8+nSULlN3e85zwvUZhk8PKBklXduxtj+N//djJkyFJOnIjBx8eLoUOb8+qrrbUBP6VUkeKZZSZB14O4N/Rt207Sq9c3nDgRw223VebPP5/hnXfaapJQHsXb25smTZrQoEED7rvvPi5cuJA6b+fOndx1113UqVOH2rVrM2bMGExKHSDw008/ERYWRr169WjatCkvvPCCHYeQrS1btvDUU0/ZHUa23nrrLWrVqkWdOnVYunRppsvccccdNGnShCZNmnDDDTfQtWtXAFatWkWpUqVS540ePRqAy5cv06pVKxITE/PnIIwxHvV3cyWMmVnduENiYlK68SFDlpiZMzebpKRkt+xPFW67du2yOwRTrFix1OHHHnvMjB071hhjTGxsrKlRo4ZZunSpMcaYixcvmg4dOpjJkycbY4zZsWOHqVGjhtm9e7cxxpjExEQzderUPI0tISHhmrfx4IMPmq1bt+brPq/Gzp07TaNGjUxcXJw5ePCgqVGjhklMTMx2nW7dupn//Oc/xhhjVq5caTp16pTpcq+//rqZO3dupvMye+8Bm0wuv3c9r+gJ3NKr3cqVh+jffzEzZnSmVSurWGvChPZ5vh9VRL3vprqKF0zOyzi0aNGC7dutpmW++OILWrZsSbt21t2DQUFBTJ48mTZt2jBgwADGjx/PyJEjqVu3LmBdmfTr1++KbcbExPDcc8+xadMmRITXXnuN7t27U7x4cWJiYgCYP38+P/74I3PmzOGJJ54gICCALVu20LJlS7799lu2bt1K6dLWzSm1a9fm999/x8vLi759+3L06FEAPvzwQ1q2bJlu39HR0Wzfvp3GjRsDsGHDBp5//nni4uIIDAxk9uzZ1KlThzlz5vDtt98SExNDUlISv/76K++++y5fffUV8fHxPPDAA7zxxhsAdO3alWPHjhEXF8fzzz/PM8884/L5zcz3339Pz5498ff3p3r16tSqVYsNGzbQokWLTJePioril19+Yfbs2Tluu2vXrowYMYLevXtfU4yu8MxEEZB3/WSfOnWRYcOW8dln2wCYMOGP1EShVGGRlJTEihUrUotpdu7cyc0335xumZo1axITE0NUVBR//fWXS0VNY8aMoVSpUuzYsQOA8+fP57hOeHg4a9euxdvbm6SkJL777juefPJJ1q9fT9WqVSlfvjyPPPIIQ4YM4fbbb+fo0aO0b9+e3bt3p9vOpk2baNAgrQWEunXr8ttvv+Hj48Py5ct5+eWX+eYbqwHRP//8k+3bt1O2bFl+/vln9u3bx4YNGzDG0KVLF1avXk2rVq2YNWsWZcuW5dKlS9xyyy10796d4OD0vWgOGTKElStXXnFcPXv25KWXXko3LSIigubNm6eOV6pUiYiIiCzPzYIFC7j77rspWbJk6rQ//viDxo0bc8MNN/Dee+9Rv359ABo0aMDGjRtzOt15wjMThfe1txqbnGz49NM/GT58OefPx+Hv782oUa0YNuy2PAhQqQyu4pd/Xrp06RJNmjQhIiKC0NBQ2rZtm6fbX758OfPmzUsdL1Mm5x9xDz30EN7e3gD06NGD0aNH8+STTzJv3jx69OiRut1du3alrhMVFUVMTAzFi6c10X/8+HHKlSuXOh4ZGcnjjz/Ovn37EBESEhJS57Vt25ayZcsC8PPPP/Pzzz/TtGlTwLoq2rdvH61atWLSpEl89913ABw7dox9+/ZdkSg++OAD105OLnz55Zf8+9//Th2/6aabOHLkCMWLF2fx4sV07dqVffv2AdZVnp+fH9HR0ZQoUcJtMYHHJgr/a1r90KHzPProd6xdewyAdu1qMmVKR2rVKpsX0SlVYAQGBrJ161ZiY2Np3749U6ZMYdCgQdSrV4/Vq1enW/bgwYMUL16ckiVLUr9+fTZv3pxarHO1nG/RzHhPf7FixVKHW7Rowf79+zl9+jQLFixg1KhRACQnJ7Nu3ToCArL+URgYGJhu26+88gp33nkn3333HYcPH6ZNmzaZ7tMYw4gRI3j22WfTbW/VqlUsX76cP/74g6CgINq0aZPp8whXc0VRsWJFjh07ljoeHh5OxYqZt1F35swZNmzYkJqogHRXFh07dqR///6cOXOGkJAQAOLj47M9R3nFM+96Srh4TauXLOnP3r1nuf764syb150lS3prklCFWlBQEJMmTeL9998nMTGR3r178/vvv7N8ufXw6KVLlxg0aBAvvvgiAMOGDePNN99k7969gPXFPX369Cu227ZtW6ZMmZI6nlL0VL58eXbv3k1ycnK6L76MRIQHHniAoUOHEhoamvrrvV27dnz00Uepy23duvWKdUNDQ9m/P62V5sjIyNQv4Tlz5mS5z/bt2zNr1qzUOpSIiAhOnTpFZGQkZcqUISgoiD179rBu3bpM1//ggw/YunXrFX8ZkwRAly5dmDdvHvHx8Rw6dIh9+/bRrFmzTLc7f/58OnfunO6L/8SJE6l3om3YsIHk5OTUc3T27FlCQkLytKmOrHhmosjFw3ZLl+4nPt66lSw4OIiFC3uyZ88AevRooA9FqSKhadOmNGrUiC+//JLAwEC+//57xo4dS506dWjYsCG33HILAwcOBKBRo0Z8+OGH9OrVi9DQUBo0aMDBgwev2OaoUaM4f/48DRo0oHHjxqm/tN9++206d+7MbbfdRoUKFbKNq0ePHsydOze12Alg0qRJbNq0iUaNGlGvXr1Mk1TdunWJjIwkOtpqreHFF19kxIgRNG3aNNvbRtu1a8cjjzxCixYtaNiwIQ8++CDR0dF06NCBxMREQkNDeemll9LVLeRW/dZ/BsEAAAo0SURBVPr1efjhh6lXrx4dOnRgypQpqcVuHTt25J9//klddt68efTq1Svd+vPnz089t4MGDWLevHmp31crV66kU6dO1xyjKyQlW3mKsMpiNi2YADcPcWn5Y8ciGTRoCQsW7GHMmDsZNaqVmyNUyrJ7925CQ0PtDqNQ++CDDyhRokS6cv2iolu3brz99tvceOONV8zL7L0nIpuNMWG52ZdnXlHc+FCOiyQmJjNhwh+Ehk5hwYI9FC/uR9my2vy3UoVJv3798Pe/tjpLT3T58mW6du2aaZJwB8+szPbJ/gt/3bpw+vb9kW3bTgLQvXsoEyd2oGLFktmup5TyLAEBAfTp08fuMPKdn58fjz32WL7tzzMTRTbWrw/ntts+xRioVq00kyffS6dO+ZN1lcrIGKN1YCpfuaM6odAlimbNKtK+fS2aNr2eUaNaERTk/jsClMpMQEAAZ8+e1abGVb4xjv4o8vqWWY9PFPv2nWXIkKVMmNCeG2+0PpCLFv1/e/cfLGVVx3H8/eGXF9PBlLHRsK4OiKACERnlTIagQ2gwFcOPAIXBDIoaNfujwSb6MUpjNhOhXUkdwBExKPIOUebQVYIBhJJfkj8QGL3lBCYxjeAtrt/+OOe622Xv7nNvd5/99X3N3JndZ8/zPN/7nd09e86z+z1fpEcPf2G60howYADNzc0cPXq01KG4GtK2wl13qtiOoqXlFIsXb+aeezbT0tJKXV0v1q6dAuCdhCsLvXv37tZVxpwrlaJ+60nSeEkvSTog6bRfo0g6Q9IT8fHtkuqTHHdj0+sMG9bAokXP0tLSypw5I2houLG7w3fOOUcRRxSSegL3A9cBzcAOSY1mtj+r2VzgmJkNlDQN+CEw9fSjZRx66xzG3fAkAEOG9Keh4UYv4uecc0VUzBHFVcABMztoZv8GVgOT2rWZBKyIt9cCY1Xgqt+xE32pq+vJ3Xdfy65d87yTcM65IivaL7MlTQbGm9kt8f4s4ONmtiCrzb7YpjnefzW2ebPdsW4F2grDXwHsK0rQlac/8GbBVrXBc5HhucjwXGQMNrMulZmtiIvZZrYMWAYgaWdXf4ZebTwXGZ6LDM9FhuciQ9LOru5bzKmnvwIXZd0fELflbCOpF9AP+EcRY3LOOddJxewodgCDJF0sqQ8wDWhs16YRuDnengz8wSqtSqFzzlW5ok09mdkpSQuAp4CewCNm9oKk7xEW+W4EHgYelXQAeIvQmRSyrFgxVyDPRYbnIsNzkeG5yOhyLiquzLhzzrl0VWaZceecc6nxjsI551xeZdtRFKv8RyVKkIs7JO2XtEfSRklV+yvEQrnIavcFSSapar8amSQXkqbE58YLklalHWNaErxGPiSpSdLz8XUyoRRxFpukRyQdib9Ry/W4JC2JedojaWSiA5tZ2f0RLn6/ClwC9AF2A0PbtfkK0BBvTwOeKHXcJczFGODMeHt+Lecitjsb2ARsA0aVOu4SPi8GAc8D74/3zy913CXMxTJgfrw9FDhc6riLlItPASOBfR08PgH4LSBgNLA9yXHLdURRlPIfFapgLsysycxOxLvbCL9ZqUZJnhcA3yfUDXsnzeBSliQXXwLuN7NjAGZ2JOUY05IkFwa0LXHZD/hbivGlxsw2Eb5B2pFJwEoLtgHnSLqg0HHLtaP4IPB61v3muC1nGzM7BRwHzkslunQlyUW2uYRPDNWoYC7iUPoiM/tNmoGVQJLnxaXApZK2SNomaXxq0aUrSS4WATMlNQMbgK+lE1rZ6ez7CVAhJTxcMpJmAqOAa0odSylI6gH8GJhd4lDKRS/C9NOnCaPMTZKuNLN/ljSq0pgOLDez+yR9gvD7rSvM7N1SB1YJynVE4eU/MpLkAknjgIXARDNrSSm2tBXKxdmEopHPSDpMmINtrNIL2kmeF81Ao5n9x8wOAS8TOo5qkyQXc4FfAJjZVqCOUDCw1iR6P2mvXDsKL/+RUTAXkj4CPEjoJKp1HhoK5MLMjptZfzOrN7N6wvWaiWbW5WJoZSzJa+TXhNEEkvoTpqIOphlkSpLk4jVgLICkIYSOohbXqG0EborffhoNHDezNwrtVJZTT1a88h8VJ2Eu7gXOAtbE6/mvmdnEkgVdJAlzURMS5uIp4HpJ+4FW4JtmVnWj7oS5+Abwc0m3Ey5sz67GD5aSHid8OOgfr8d8B+gNYGYNhOszE4ADwAlgTqLjVmGunHPOdaNynXpyzjlXJryjcM45l5d3FM455/LyjsI551xe3lE455zLyzsKV3YktUralfVXn6dtfUeVMjt5zmdi9dHdseTF4C4cY56km+Lt2ZIuzHrsIUlDuznOHZJGJNjnNkln/r/ndrXLOwpXjk6a2Yisv8MpnXeGmQ0nFJu8t7M7m1mDma2Md2cDF2Y9douZ7e+WKDNxPkCyOG8DvKNwXeYdhasIceTwR0l/jn+fzNHmcknPxVHIHkmD4vaZWdsflNSzwOk2AQPjvmPjGgZ7Y63/M+L2xcqsAfKjuG2RpDslTSbU3HosnrNvHAmMiqOO997c48hjaRfj3EpWQTdJP5O0U2Htie/GbV8ndFhNkprituslbY15XCPprALncTXOOwpXjvpmTTuti9uOANeZ2UhgKrAkx37zgJ+Y2QjCG3VzLNcwFbg6bm8FZhQ4/2eBvZLqgOXAVDO7klDJYL6k84DPAZeb2TDgB9k7m9laYCfhk/8IMzuZ9fAv475tpgKruxjneEKZjjYLzWwUMAy4RtIwM1tCKKk9xszGxFIedwHjYi53AncUOI+rcWVZwsPVvJPxzTJbb2BpnJNvJdQtam8rsFDSAOBXZvaKpLHAR4EdsbxJX0Knk8tjkk4ChwllqAcDh8zs5fj4CuCrwFLCWhcPS1oPrE/6j5nZUUkHY52dV4DLgC3xuJ2Jsw+hbEt2nqZIupXwur6AsEDPnnb7jo7bt8Tz9CHkzbkOeUfhKsXtwN+B4YSR8GmLEpnZKknbgRuADZK+TFjJa4WZfSvBOWZkFxCUdG6uRrG20FWEInOTgQXAtZ34X1YDU4AXgXVmZgrv2onjBP5EuD7xU+Dzki4G7gQ+ZmbHJC0nFL5rT8DTZja9E/G6GudTT65S9APeiOsHzCIUf/sfki4BDsbplicJUzAbgcmSzo9tzlXyNcVfAuolDYz3ZwHPxjn9fma2gdCBDc+x778IZc9zWUdYaWw6odOgs3HGgnbfBkZLuoywetvbwHFJHwA+00Es24Cr2/4nSe+TlGt05tx7vKNwleIB4GZJuwnTNW/naDMF2CdpF2FdipXxm0Z3Ab+XtAd4mjAtU5CZvUOorrlG0l7gXaCB8Ka7Ph5vM7nn+JcDDW0Xs9sd9xjwF+DDZvZc3NbpOOO1j/sIVWF3E9bHfhFYRZjOarMM+J2kJjM7SvhG1uPxPFsJ+XSuQ1491jnnXF4+onDOOZeXdxTOOefy8o7COedcXt5ROOecy8s7Cuecc3l5R+Gccy4v7yicc87l9V8qcNDLgmOArQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#save keras model\n",
    "model_json = model8ec.to_json()\n",
    "with open(\"models/convlstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model8ec.save_weights(\"models/convlstm.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47000, 98, 30)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-d4a9cb17eacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "model.add(LSTM(25))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(100,activation='tanh'))\n",
    "model.add(Dense(25,activation='tanh'))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "model.add(Dense(10,activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10,batch_size=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296/5296 [==============================] - 4s 700us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.35045317220543"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 98, 100)           55200     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 50)                25200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 88,296\n",
      "Trainable params: 88,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 21052 samples, validate on 5296 samples\n",
      "Epoch 1/3\n",
      "21052/21052 [==============================] - 296s 14ms/step - loss: 2.6245 - acc: 0.5937 - val_loss: 6.0017 - val_acc: 0.6276\n",
      "Epoch 2/3\n",
      "21052/21052 [==============================] - 287s 14ms/step - loss: 6.1935 - acc: 0.6152 - val_loss: 6.0017 - val_acc: 0.6276\n",
      "Epoch 3/3\n",
      "21052/21052 [==============================] - 288s 14ms/step - loss: 6.0240 - acc: 0.6260 - val_loss: 6.0017 - val_acc: 0.6276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1b79b9240>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelq = Sequential()\n",
    "modelq.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "modelq.add(Bidirectional(LSTM(25,activation='selu')))\n",
    "modelq.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "modelq.add(Dense(100,activation='selu'))\n",
    "modelq.add(Dense(25,activation='selu'))\n",
    "#model.add(Dense(20,activation='tanh'))\n",
    "modelq.add(Dense(10,activation='selu'))\n",
    "modelq.add(Dense(1, activation='sigmoid'))\n",
    "modelq.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(modelq.summary())\n",
    "modelq.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=3,batch_size=8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296/5296 [==============================] - 4s 755us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62.7643504531722"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = modelq.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#save keras model\n",
    "model_json = modelq.to_json()\n",
    "with open(\"models/model4times_100batch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "modelq.save_weights(\"models/model4times_100batch.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 98, 100)           55200     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 128,496\n",
      "Trainable params: 128,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 21000 samples, validate on 5348 samples\n",
      "Epoch 1/10\n",
      "21000/21000 [==============================] - 125s 6ms/step - loss: 0.6482 - acc: 0.6356 - val_loss: 0.6413 - val_acc: 0.6460\n",
      "Epoch 2/10\n",
      "21000/21000 [==============================] - 119s 6ms/step - loss: 0.6423 - acc: 0.6405 - val_loss: 0.6398 - val_acc: 0.6485\n",
      "Epoch 3/10\n",
      "21000/21000 [==============================] - 121s 6ms/step - loss: 0.6429 - acc: 0.6380 - val_loss: 0.6397 - val_acc: 0.6460\n",
      "Epoch 4/10\n",
      "21000/21000 [==============================] - 121s 6ms/step - loss: 0.6412 - acc: 0.6402 - val_loss: 0.6387 - val_acc: 0.6451\n",
      "Epoch 5/10\n",
      "21000/21000 [==============================] - 120s 6ms/step - loss: 0.6406 - acc: 0.6404 - val_loss: 0.6389 - val_acc: 0.6483\n",
      "Epoch 6/10\n",
      "21000/21000 [==============================] - 121s 6ms/step - loss: 0.6394 - acc: 0.6414 - val_loss: 0.6392 - val_acc: 0.6455\n",
      "Epoch 7/10\n",
      "21000/21000 [==============================] - 120s 6ms/step - loss: 0.6382 - acc: 0.6423 - val_loss: 0.6384 - val_acc: 0.6481\n",
      "Epoch 8/10\n",
      "21000/21000 [==============================] - 122s 6ms/step - loss: 0.6365 - acc: 0.6428 - val_loss: 0.6353 - val_acc: 0.6487\n",
      "Epoch 9/10\n",
      "21000/21000 [==============================] - 121s 6ms/step - loss: 0.6369 - acc: 0.6434 - val_loss: 0.6359 - val_acc: 0.6507\n",
      "Epoch 10/10\n",
      "21000/21000 [==============================] - 120s 6ms/step - loss: 0.6370 - acc: 0.6425 - val_loss: 0.6390 - val_acc: 0.6369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88b7f81400>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb = Sequential()\n",
    "modelb.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "modelb.add(Bidirectional(LSTM(50),merge_mode='concat'))\n",
    "modelb.add(Dropout(0.2))\n",
    "#modelb.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "modelb.add(Dense(100,activation='tanh'))\n",
    "modelb.add(Dense(25,activation='tanh'))\n",
    "modelb.add(Dense(10,activation='tanh'))\n",
    "modelb.add(Dense(1, activation='sigmoid'))\n",
    "modelb.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(modelb.summary())\n",
    "modelb.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10,batch_size=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5348/5348 [==============================] - 13s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.68735976065819"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresb = modelb.evaluate(X_test, Y_test)\n",
    "scoresb[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#save keras model\n",
    "model_json = modelb.to_json()\n",
    "with open(\"models/model4times_10epoch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "modelb.save_weights(\"models/model4times_10epoch.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "cnt = 0\n",
    "anss = []\n",
    "class CLSTM(object):\n",
    "    def __init__(self):\n",
    "        # define lower bound of benchmark function\n",
    "        self.Lower = 0\n",
    "        # define upper bound of benchmark function\n",
    "        self.Upper = 1\n",
    "\n",
    "    # function which returns evaluate function\n",
    "    def function(self):\n",
    "        def evalute(D,sol):\n",
    "            global cnt\n",
    "            cnt = cnt +1\n",
    "            print(cnt,end=\" \")\n",
    "            from keras.models import Sequential\n",
    "            from keras.layers import Dense\n",
    "            from keras.layers import LSTM\n",
    "            from keras.layers import Dropout,Bidirectional\n",
    "            from keras.layers import Reshape,MaxPooling1D,Conv1D\n",
    "            from keras.layers import Reshape\n",
    "            sol = np.array(sol)\n",
    "            sol = sigmoid(sol)\n",
    "            #display(sol)\n",
    "            op = sol>=0.6\n",
    "            X_tr = X_train[:,:,op]\n",
    "            X_te = X_test[:,:,op]\n",
    "            X_tr  = X_tr.reshape((X_tr.shape[0],1,X_tr.shape[1],X_tr.shape[2]))\n",
    "            X_te  = X_te.reshape((X_te.shape[0],1,X_te.shape[1],X_te.shape[2]))\n",
    "            modelf = Sequential()\n",
    "            modelf.add(Conv2D(45, (5,5), input_shape=(X_tr.shape[1],X_tr.shape[2],X_tr.shape[3]), activation='relu', padding='same'))\n",
    "            modelf.add(Reshape((98,45)))\n",
    "            modelf.add(LSTM(100,input_shape=(98,45)))\n",
    "            #model8ec.add(Bidirectional(LSTM(25)))\n",
    "            modelf.add(Dropout(0.2))\n",
    "            #model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "            modelf.add(Dense(100,activation='tanh'))\n",
    "            modelf.add(Dense(25,activation='tanh'))\n",
    "            #model.add(Dense(20,activation='tanh'))\n",
    "            modelf.add(Dense(10,activation='tanh'))\n",
    "            modelf.add(Dense(1, activation='sigmoid'))\n",
    "            modelf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            modelf.fit(X_tr, Y_train, validation_data=(X_te, Y_test), epochs=30,batch_size=1000,verbose=0)\n",
    "            scores = modelf.evaluate(X_te, Y_test, verbose=0)\n",
    "            anss.append((scores[1],modelf,op))\n",
    "            k = -1*scores[1]\n",
    "            return k\n",
    "        return evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "cnt = 0\n",
    "anss = []\n",
    "class LSTM(object):\n",
    "    def __init__(self):\n",
    "        # define lower bound of benchmark function\n",
    "        self.Lower = -10\n",
    "        # define upper bound of benchmark function\n",
    "        self.Upper = 10\n",
    "\n",
    "    # function which returns evaluate function\n",
    "    def function(self):\n",
    "        def evalute(D,sol):\n",
    "            global cnt\n",
    "            cnt = cnt +1\n",
    "            print(cnt,end=\" \")\n",
    "            from keras.models import Sequential\n",
    "            from keras.layers import Dense\n",
    "            from keras.layers import LSTM\n",
    "            from keras.layers import Dropout,Bidirectional\n",
    "            from keras.layers import Reshape,MaxPooling1D,Conv1D\n",
    "            sol = np.array(sol)\n",
    "            sol = sigmoid(sol)\n",
    "            #display(sol)\n",
    "            op = sol>=0.6\n",
    "            X_tr = X_train[:,:,op]\n",
    "            X_te = X_test[:,:,op]\n",
    "            model8 = Sequential()\n",
    "            model8.add(LSTM(100, input_shape=(X_tr.shape[1],X_tr.shape[2]),return_sequences=True))\n",
    "            model8.add(LSTM(50))\n",
    "            model8.add(Dropout(0.2))\n",
    "            #model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "            model8.add(Dense(100,activation='tanh'))\n",
    "            model8.add(Dense(25,activation='tanh'))\n",
    "            #model.add(Dense(20,activation='tanh'))\n",
    "            model8.add(Dense(10,activation='tanh'))\n",
    "            model8.add(Dense(1, activation='sigmoid'))\n",
    "            model8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            model8.fit(X_tr, Y_train, validation_data=(X_te, Y_test), epochs=30,batch_size=500,verbose=0)\n",
    "            scores = model8.evaluate(X_te, Y_test, verbose=0)\n",
    "            anss.append((scores[1],model8,op))\n",
    "            k = -1*scores[1]\n",
    "            return k\n",
    "        return evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 "
     ]
    }
   ],
   "source": [
    "from NiaPy.algorithms.basic import BatAlgorithm\n",
    "for i in range(2):\n",
    "    algorithm = BatAlgorithm(D=30, NP=60, nFES=5, benchmark=LSTM(),A=5,Qmin=1,Qmax=10)\n",
    "    best = algorithm.run()\n",
    "    print(best)\n",
    "    ans.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 (array([-1.03677143, -1.36227827, -1.26956162, -0.06191066, -1.11486151,\n",
      "        0.28137677, -0.66608563,  0.12486249,  3.79787069, -1.29366782,\n",
      "        8.57862676,  0.29652815, -2.90199104, -2.56500628, -5.32347959,\n",
      "       -2.6554794 ,  1.33560278,  2.6861549 ,  3.60076783, -3.24866476,\n",
      "        4.55385392,  6.22742984,  7.45411631,  5.0224634 , -5.08073079,\n",
      "       -2.82359487, -0.85261505, -7.41957479, -1.00675362,  1.97277354]), -0.7010200154423438)\n"
     ]
    }
   ],
   "source": [
    "from NiaPy.algorithms.basic import GreyWolfOptimizer\n",
    "for i in range(1):\n",
    "    algorithm = GreyWolfOptimizer(D=30, NP=60, nFES=5, benchmark=CLSTM())\n",
    "    best = algorithm.run()\n",
    "    print(best)\n",
    "    ans.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-1.03677143, -1.36227827, -1.26956162, -0.06191066, -1.11486151,\n",
       "          0.28137677, -0.66608563,  0.12486249,  3.79787069, -1.29366782,\n",
       "          8.57862676,  0.29652815, -2.90199104, -2.56500628, -5.32347959,\n",
       "         -2.6554794 ,  1.33560278,  2.6861549 ,  3.60076783, -3.24866476,\n",
       "          4.55385392,  6.22742984,  7.45411631,  5.0224634 , -5.08073079,\n",
       "         -2.82359487, -0.85261505, -7.41957479, -1.00675362,  1.97277354]),\n",
       "  -0.7010200154423438)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7010200154423438,\n",
       "  <keras.engine.sequential.Sequential at 0x7f80607da390>,\n",
       "  array([ True, False,  True, False, False,  True, False, False,  True,\n",
       "         False, False, False, False,  True,  True,  True, False,  True,\n",
       "         False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "          True,  True,  True])),\n",
       " (0.6612779060816012,\n",
       "  <keras.engine.sequential.Sequential at 0x7f8034011ba8>,\n",
       "  array([False, False,  True, False,  True, False, False, False, False,\n",
       "         False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True, False, False])),\n",
       " (0.6439568899153195,\n",
       "  <keras.engine.sequential.Sequential at 0x7f802c075470>,\n",
       "  array([ True, False,  True, False, False, False, False, False,  True,\n",
       "          True, False, False, False, False,  True,  True, False, False,\n",
       "          True,  True, False,  True, False, False,  True, False,  True,\n",
       "          True,  True,  True])),\n",
       " (0.6781177829558157,\n",
       "  <keras.engine.sequential.Sequential at 0x7f802adad4a8>,\n",
       "  array([False, False,  True, False,  True, False,  True,  True, False,\n",
       "          True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "          True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "          True,  True,  True])),\n",
       " (0.6837952270977675,\n",
       "  <keras.engine.sequential.Sequential at 0x7f8029adbe48>,\n",
       "  array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "          True,  True, False,  True,  True,  True,  True, False, False,\n",
       "          True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False]))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 98, 100)           47600     \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 85,696\n",
      "Trainable params: 85,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bat = anss[6][1]\n",
    "og = anss[6][2]\n",
    "model_bat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 98, 45)         19170     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 98, 45)            0         \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 100)               58400     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 90,466\n",
      "Trainable params: 90,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gwo = anss[0][1]\n",
    "og = anss[0][2]\n",
    "model_gwo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10392, 98, 17)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teee = X_test[:,:,og]\n",
    "X_teee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5449572807096169, 0.7041955350728288]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = model_bat.evaluate(X_teee,Y_test)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teee  = X_teee.reshape((X_teee.shape[0],1,X_teee.shape[1],X_teee.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10392/10392 [==============================] - 7s 721us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5697576119130717, 0.7010200154423438]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = model_gwo.evaluate(X_teee,Y_test)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2962578 ],\n",
       "       [0.1713198 ],\n",
       "       [0.47056663],\n",
       "       ...,\n",
       "       [0.28802007],\n",
       "       [0.23014206],\n",
       "       [0.38112417]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_gwo.predict(X_teee)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26770320601968933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46770601336302897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0.69893743, 0.71019771]),\n",
       " array([0.9140034, 0.348659 ]),\n",
       " array([0.7921322 , 0.46770601]),\n",
       " array([6477, 3915]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7010200153964589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6299191069022947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[5920,  557],\n",
       "       [2550, 1365]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.7322967939803107,  Score/Loss : 0.26770320601968933, F1_Score_average: 0.46770601336302897, Precision, Recall, F1_score, Support: (array([0.69893743, 0.71019771]), array([0.9140034, 0.348659 ]), array([0.7921322 , 0.46770601]), array([6477, 3915]))\n",
      "F1_score_micro: 0.7010200153964589\n",
      "F1_score_macro: 0.6299191069022947\n",
      "Confusion Matrix\n",
      "[[5920  557]\n",
      " [2550 1365]]\n",
      "END\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 1.0 - roc_auc_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "display(score)\n",
    "\n",
    "\n",
    "f_score=f1_score(Y_test,y_pred.round())\n",
    "\n",
    "display(f_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prfs=precision_recall_fscore_support(Y_test,y_pred.round())\n",
    "\n",
    "\n",
    "display(prfs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_score_micro=f1_score(Y_test,y_pred.round(),average='micro')\n",
    "f_score_macro=f1_score(Y_test,y_pred.round(),average='macro')\n",
    "\n",
    "display(f_score_micro)\n",
    "display(f_score_macro)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf=confusion_matrix(Y_test,y_pred.round())\n",
    "\n",
    "display(cf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUC : \"+str(1.0 - score)+\",  Score/Loss : \"+str(score)+\", F1_Score_average: \"+str(f_score)+\", Precision, Recall, F1_score, Support: \"+str(prfs))\n",
    "print(\"F1_score_micro: \"+str(f_score_micro))\n",
    "print(\"F1_score_macro: \"+str(f_score_macro))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cf)\n",
    "print(\"END\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7322967939803107}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# In[271]:\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[1], tpr[1], _ = roc_curve(Y_test[:, 0], y_pred[:, 0])\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])\n",
    "\n",
    "\n",
    "# In[272]:\n",
    "\n",
    "\n",
    "display(roc_auc)\n",
    "\n",
    "\n",
    "# In[275]:\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable= False\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

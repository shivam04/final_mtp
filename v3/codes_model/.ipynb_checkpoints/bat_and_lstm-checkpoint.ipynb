{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2561,
     "status": "ok",
     "timestamp": 1558599442118,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "yqlh38dkuyru",
    "outputId": "48b3a7fc-7639-43da-d16d-4e46d8f8fe9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed,AveragePooling1D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21750,
     "status": "ok",
     "timestamp": 1558599425677,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "2Ur9JOS6w3_L",
    "outputId": "0d396d64-ec8a-43ac-f2a8-9ce6000bce29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting NiaPy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/1a/f1f82026e69178c09d71238d19e6b04952c7e3d53964d7123aee00debdd6/NiaPy-1.0.2-py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.7MB/s \n",
      "\u001b[?25hCollecting xlsxwriter~=1.0.2 (from NiaPy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/52/7f526f085be203d539567ac9e49042590254050a53d50acd59cea99c681e/XlsxWriter-1.0.9-py2.py3-none-any.whl (141kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 5.7MB/s \n",
      "\u001b[?25hCollecting scipy~=1.0.0 (from NiaPy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/13/eb888fcc83f14d114dee794c3491477ce156caa9f456b7bef1112dde36b5/scipy-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
      "\u001b[K     |████████████████████████████████| 50.0MB 869kB/s \n",
      "\u001b[?25hCollecting numpy~=1.14.0 (from NiaPy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K     |████████████████████████████████| 13.8MB 19.5MB/s \n",
      "\u001b[?25hCollecting click~=6.0 (from NiaPy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 18.9MB/s \n",
      "\u001b[31mERROR: spacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.52 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: cvxpy 1.0.15 has requirement scipy>=1.1.0, but you'll have scipy 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter, numpy, scipy, click, NiaPy\n",
      "  Found existing installation: numpy 1.16.3\n",
      "    Uninstalling numpy-1.16.3:\n",
      "      Successfully uninstalled numpy-1.16.3\n",
      "  Found existing installation: scipy 1.3.0\n",
      "    Uninstalling scipy-1.3.0:\n",
      "      Successfully uninstalled scipy-1.3.0\n",
      "  Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "Successfully installed NiaPy-1.0.2 click-6.7 numpy-1.14.6 scipy-1.0.1 xlsxwriter-1.0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy",
         "scipy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install NiaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5211,
     "status": "ok",
     "timestamp": 1558599131263,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "w13FhJNmvozI",
    "outputId": "d07479d5-e3a2-423f-f55f-f77741f95a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-23 08:12:08--  https://www.dropbox.com/s/rppw0q78nk03644/patient_data_24_hours.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6031:1::a27d:5101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/rppw0q78nk03644/patient_data_24_hours.csv [following]\n",
      "--2019-05-23 08:12:08--  https://www.dropbox.com/s/raw/rppw0q78nk03644/patient_data_24_hours.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com/cd/0/inline/Aha-tNs3zHvUZnBYtAP4sJFfLh0f4n0_a9d2h2tN-Xc61-VXi5uJPJ2aQ5iot-hSzsn5WHutPoWa8pmFJeVmOk5tIR0TrbI_qxUXV6ghiYPvvA/file# [following]\n",
      "--2019-05-23 08:12:09--  https://uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com/cd/0/inline/Aha-tNs3zHvUZnBYtAP4sJFfLh0f4n0_a9d2h2tN-Xc61-VXi5uJPJ2aQ5iot-hSzsn5WHutPoWa8pmFJeVmOk5tIR0TrbI_qxUXV6ghiYPvvA/file\n",
      "Resolving uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com (uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
      "Connecting to uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com (uc1c7cf587874a6afb5d4f1c9a3f.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 62249891 (59M) [text/plain]\n",
      "Saving to: ‘patient_data_24_hours.csv’\n",
      "\n",
      "patient_data_24_hou 100%[===================>]  59.37M  73.1MB/s    in 0.8s    \n",
      "\n",
      "2019-05-23 08:12:10 (73.1 MB/s) - ‘patient_data_24_hours.csv’ saved [62249891/62249891]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/2qkkea4nxbzh7w1/outcomes.csv\n",
    "!wget https://www.dropbox.com/s/rppw0q78nk03644/patient_data_24_hours.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2434
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2523,
     "status": "ok",
     "timestamp": 1558599447053,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "PbSmQwQjuyr-",
    "outputId": "c1f8d03d-9cdc-452a-9405-5cba67e4e64e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Alk. Phosphate</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Total Bili</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>...</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>Arterial BP [Systolic]</th>\n",
       "      <th>Temperature C</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Previous WeightF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103116</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.445489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.387218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 23:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.387218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 22:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.372180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 21:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 20:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.334586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 19:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 17:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.262376</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 16:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 15:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 14:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.390977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 13:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.390977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 18:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 11:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 12:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 02:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 03:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.379699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 04:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.439850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 05:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.439850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 01:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.445489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 07:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 08:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 09:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 10:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17</td>\n",
       "      <td>0 days 06:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.439850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 13:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 14:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 15:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 16:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 17:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 21:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 20:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 22:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.462406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 23:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.462406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.462406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 19:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.212871</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.379699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 12:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 18:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.212871</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.390977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 10:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 01:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 02:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 03:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 04:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 05:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.183168</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 06:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 09:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 11:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 07:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21</td>\n",
       "      <td>0 days 08:00:00.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046314</td>\n",
       "      <td>0.228866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID                  TimeStamp  Albumin  Alk. Phosphate       ALT  \\\n",
       "0           17  0 days 00:00:00.000000000      0.0        0.000000  0.000000   \n",
       "1           17  1 days 00:00:00.000000000      0.0        0.000000  0.000000   \n",
       "2           17  0 days 23:00:00.000000000      0.0        0.000000  0.000000   \n",
       "3           17  0 days 22:00:00.000000000      0.0        0.000000  0.000000   \n",
       "4           17  0 days 21:00:00.000000000      0.0        0.000000  0.000000   \n",
       "5           17  0 days 20:00:00.000000000      0.0        0.000000  0.000000   \n",
       "6           17  0 days 19:00:00.000000000      0.0        0.000000  0.000000   \n",
       "7           17  0 days 17:00:00.000000000      0.0        0.000000  0.000000   \n",
       "8           17  0 days 16:00:00.000000000      0.0        0.000000  0.000000   \n",
       "9           17  0 days 15:00:00.000000000      0.0        0.000000  0.000000   \n",
       "10          17  0 days 14:00:00.000000000      0.0        0.000000  0.000000   \n",
       "11          17  0 days 13:00:00.000000000      0.0        0.000000  0.000000   \n",
       "12          17  0 days 18:00:00.000000000      0.0        0.000000  0.000000   \n",
       "13          17  0 days 11:00:00.000000000      0.0        0.000000  0.000000   \n",
       "14          17  0 days 12:00:00.000000000      0.0        0.000000  0.000000   \n",
       "15          17  0 days 02:00:00.000000000      0.0        0.000000  0.000000   \n",
       "16          17  0 days 03:00:00.000000000      0.0        0.000000  0.000000   \n",
       "17          17  0 days 04:00:00.000000000      0.0        0.000000  0.000000   \n",
       "18          17  0 days 05:00:00.000000000      0.0        0.000000  0.000000   \n",
       "19          17  0 days 01:00:00.000000000      0.0        0.000000  0.000000   \n",
       "20          17  0 days 07:00:00.000000000      0.0        0.000000  0.000000   \n",
       "21          17  0 days 08:00:00.000000000      0.0        0.000000  0.000000   \n",
       "22          17  0 days 09:00:00.000000000      0.0        0.000000  0.000000   \n",
       "23          17  0 days 10:00:00.000000000      0.0        0.000000  0.000000   \n",
       "24          17  0 days 06:00:00.000000000      0.0        0.000000  0.000000   \n",
       "25          21  0 days 13:00:00.000000000      0.0        0.017775  0.016509   \n",
       "26          21  0 days 14:00:00.000000000      0.0        0.017775  0.016509   \n",
       "27          21  0 days 15:00:00.000000000      0.0        0.017775  0.016509   \n",
       "28          21  0 days 16:00:00.000000000      0.0        0.017775  0.016509   \n",
       "29          21  0 days 17:00:00.000000000      0.0        0.017775  0.016509   \n",
       "30          21  0 days 21:00:00.000000000      0.0        0.017775  0.016509   \n",
       "31          21  0 days 20:00:00.000000000      0.0        0.017775  0.016509   \n",
       "32          21  0 days 22:00:00.000000000      0.0        0.017775  0.016509   \n",
       "33          21  0 days 23:00:00.000000000      0.0        0.017775  0.016509   \n",
       "34          21  1 days 00:00:00.000000000      0.0        0.017775  0.016509   \n",
       "35          21  0 days 19:00:00.000000000      0.0        0.017775  0.016509   \n",
       "36          21  0 days 12:00:00.000000000      0.0        0.017775  0.016509   \n",
       "37          21  0 days 18:00:00.000000000      0.0        0.017775  0.016509   \n",
       "38          21  0 days 10:00:00.000000000      0.0        0.017775  0.016509   \n",
       "39          21  0 days 01:00:00.000000000      0.0        0.017775  0.016509   \n",
       "40          21  0 days 02:00:00.000000000      0.0        0.017775  0.016509   \n",
       "41          21  0 days 03:00:00.000000000      0.0        0.017775  0.016509   \n",
       "42          21  0 days 04:00:00.000000000      0.0        0.017775  0.016509   \n",
       "43          21  0 days 05:00:00.000000000      0.0        0.017775  0.016509   \n",
       "44          21  0 days 00:00:00.000000000      0.0        0.017775  0.016509   \n",
       "45          21  0 days 06:00:00.000000000      0.0        0.017775  0.016509   \n",
       "46          21  0 days 09:00:00.000000000      0.0        0.017775  0.016509   \n",
       "47          21  0 days 11:00:00.000000000      0.0        0.017775  0.016509   \n",
       "48          21  0 days 07:00:00.000000000      0.0        0.017775  0.016509   \n",
       "49          21  0 days 08:00:00.000000000      0.0        0.017775  0.016509   \n",
       "\n",
       "         AST  Total Bili       BUN  Cholesterol  Creatinine        ...         \\\n",
       "0   0.000000         0.0  0.060606          0.0    0.013433        ...          \n",
       "1   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "2   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "3   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "4   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "5   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "6   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "7   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "8   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "9   0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "10  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "11  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "12  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "13  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "14  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "15  0.000000         0.0  0.060606          0.0    0.013433        ...          \n",
       "16  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "17  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "18  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "19  0.000000         0.0  0.060606          0.0    0.013433        ...          \n",
       "20  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "21  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "22  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "23  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "24  0.000000         0.0  0.055556          0.0    0.012687        ...          \n",
       "25  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "26  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "27  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "28  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "29  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "30  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "31  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "32  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "33  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "34  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "35  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "36  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "37  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "38  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "39  0.026735         0.0  0.479798          0.0    0.035075        ...          \n",
       "40  0.026735         0.0  0.479798          0.0    0.035075        ...          \n",
       "41  0.026735         0.0  0.479798          0.0    0.035075        ...          \n",
       "42  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "43  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "44  0.026735         0.0  0.479798          0.0    0.035075        ...          \n",
       "45  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "46  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "47  0.026735         0.0  0.520202          0.0    0.041791        ...          \n",
       "48  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "49  0.026735         0.0  0.479798          0.0    0.037313        ...          \n",
       "\n",
       "    Platelets  Respiratory Rate      SaO2  Arterial BP [Systolic]  \\\n",
       "0    0.103116          0.143564  0.990099                0.445489   \n",
       "1    0.177300          0.247525  0.990099                0.387218   \n",
       "2    0.177300          0.247525  0.990099                0.387218   \n",
       "3    0.177300          0.287129  0.990099                0.372180   \n",
       "4    0.177300          0.267327  0.990099                0.357143   \n",
       "5    0.177300          0.316832  0.990099                0.334586   \n",
       "6    0.177300          0.237624  0.990099                0.383459   \n",
       "7    0.177300          0.262376  0.990099                0.300752   \n",
       "8    0.177300          0.198020  0.990099                0.327068   \n",
       "9    0.177300          0.217822  0.990099                0.421053   \n",
       "10   0.177300          0.277228  0.990099                0.390977   \n",
       "11   0.177300          0.277228  0.990099                0.390977   \n",
       "12   0.177300          0.247525  0.990099                0.300752   \n",
       "13   0.177300          0.237624  0.990099                0.368421   \n",
       "14   0.177300          0.237624  0.990099                0.368421   \n",
       "15   0.177300          0.128713  0.990099                0.458647   \n",
       "16   0.177300          0.188119  0.990099                0.379699   \n",
       "17   0.177300          0.237624  0.990099                0.439850   \n",
       "18   0.177300          0.217822  0.990099                0.439850   \n",
       "19   0.177300          0.143564  0.990099                0.445489   \n",
       "20   0.177300          0.168317  0.990099                0.428571   \n",
       "21   0.177300          0.168317  0.990099                0.375940   \n",
       "22   0.177300          0.198020  0.990099                0.402256   \n",
       "23   0.177300          0.198020  0.990099                0.402256   \n",
       "24   0.177300          0.217822  0.990099                0.439850   \n",
       "25   0.204748          0.168317  0.990099                0.406015   \n",
       "26   0.204748          0.188119  0.990099                0.406015   \n",
       "27   0.204748          0.188119  0.990099                0.406015   \n",
       "28   0.204748          0.188119  0.990099                0.406015   \n",
       "29   0.204748          0.188119  0.990099                0.406015   \n",
       "30   0.204748          0.138614  0.990099                0.398496   \n",
       "31   0.204748          0.138614  0.990099                0.398496   \n",
       "32   0.204748          0.128713  0.990099                0.462406   \n",
       "33   0.204748          0.138614  0.990099                0.462406   \n",
       "34   0.204748          0.138614  0.990099                0.462406   \n",
       "35   0.204748          0.212871  0.990099                0.379699   \n",
       "36   0.204748          0.158416  0.990099                0.406015   \n",
       "37   0.204748          0.212871  0.990099                0.390977   \n",
       "38   0.204748          0.148515  0.990099                0.406015   \n",
       "39   0.194362          0.217822  0.990099                0.406015   \n",
       "40   0.194362          0.198020  0.990099                0.406015   \n",
       "41   0.194362          0.188119  0.990099                0.406015   \n",
       "42   0.194362          0.148515  0.990099                0.406015   \n",
       "43   0.194362          0.183168  0.990099                0.406015   \n",
       "44   0.194362          0.217822  0.990099                0.406015   \n",
       "45   0.194362          0.188119  0.990099                0.406015   \n",
       "46   0.194362          0.158416  0.990099                0.406015   \n",
       "47   0.204748          0.158416  0.990099                0.406015   \n",
       "48   0.194362          0.188119  0.990099                0.406015   \n",
       "49   0.194362          0.148515  0.990099                0.406015   \n",
       "\n",
       "    Temperature C  TroponinI  TroponinT  Urine       WBC  Previous WeightF  \n",
       "0             0.0        0.0        0.0    0.0  0.021739          0.000000  \n",
       "1             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "2             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "3             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "4             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "5             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "6             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "7             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "8             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "9             0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "10            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "11            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "12            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "13            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "14            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "15            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "16            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "17            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "18            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "19            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "20            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "21            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "22            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "23            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "24            0.0        0.0        0.0    0.0  0.047259          0.000000  \n",
       "25            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "26            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "27            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "28            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "29            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "30            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "31            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "32            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "33            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "34            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "35            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "36            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "37            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "38            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "39            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "40            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "41            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "42            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "43            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "44            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "45            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "46            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "47            0.0        0.0        0.0    0.0  0.041777          0.228866  \n",
       "48            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "49            0.0        0.0        0.0    0.0  0.046314          0.228866  \n",
       "\n",
       "[50 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../finalset/patient_data_24_hours.csv')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1558599449343,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "Cm6nrm-uuysP",
    "outputId": "a1d8dbb7-e3d0-4146-ae3b-89ca1210d98f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.02173913,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04725898,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04725898,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.79032258, 0.        , 0.00266276, ..., 0.        , 0.01587902,\n",
       "        0.        ],\n",
       "       [0.79032258, 0.        , 0.00266276, ..., 0.        , 0.01039698,\n",
       "        0.        ],\n",
       "       [0.79032258, 0.        , 0.00266276, ..., 0.        , 0.01587902,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D = np.array(df.drop(['SUBJECT_ID', 'TimeStamp'], 1))\n",
    "matrix3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1707,
     "status": "ok",
     "timestamp": 1558599451392,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "juTY2t3Suysc",
    "outputId": "79e321e6-0617-494e-fbe3-234504c49cf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164675, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1558599453192,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "tUyY3Ko8uysq",
    "outputId": "abcee793-3593-42b0-f2a7-7cf90885afb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 25, 37)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3D = np.array(matrix3D).reshape((6587, 25, 37))\n",
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1237,
     "status": "ok",
     "timestamp": 1558599454929,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "If9HRhjHuys2",
    "outputId": "a2cb13df-8332-4a8e-e800-57a5ee4750b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  LABEL\n",
       "0          17      0\n",
       "1          21      0\n",
       "2          23      0\n",
       "3          34      0\n",
       "4          36      1\n",
       "5          61      0\n",
       "6          68      1\n",
       "7          85      0\n",
       "8          94      0\n",
       "9         103      1"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "outcomes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1340,
     "status": "ok",
     "timestamp": 1558599458354,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "sK-gokfCuytC",
    "outputId": "426611b9-bcd6-4194-e6d9-7b92812a9b17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(outcomes.drop(['SUBJECT_ID'], 1))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1558599459549,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "ybSlkEq3uytR",
    "outputId": "f74ea8df-b534-4588-d12b-b084a71c0375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6587, 25, 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = matrix3D\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1558599461603,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "yVmuBVuauytg",
    "outputId": "af6e4415-ac0b-4eb3-c982-58ed37ee563f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5270, 25, 37)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1317, 25, 37)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5270, 1)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1317, 1)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X[:5270]\n",
    "X_test = X[5270:]\n",
    "Y_train = Y[:5270]\n",
    "Y_test = Y[5270:]\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15908,
     "status": "error",
     "timestamp": 1558599324437,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "BYUj6IvOuyts",
    "outputId": "ea71b5e3-07f0-4c79-f391-3bd015c59311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 25, 37)            11100     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 25, 1)             38        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 11,164\n",
      "Trainable params: 11,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5270 samples, validate on 1317 samples\n",
      "Epoch 1/30\n",
      "1424/5270 [=======>......................] - ETA: 36s - loss: 0.2346 - acc: 0.6208"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-001055965269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(37, input_shape=(25, 37),return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhtkP4zNuyt7",
    "outputId": "25c5f945-4250-47a0-eba8-2f0be0caa544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 [==============================] - 0s 138us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.884586189765315"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZ9zrv9yuyuJ",
    "outputId": "7c70ef7b-140d-436f-caf8-29eb901b1e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43351284, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.32689171, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.32689171, -0.52433825],\n",
       "        ...,\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.32689171, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.32689171, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.32689171, -0.52433825]],\n",
       "\n",
       "       [[-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.34979551,  0.43185661],\n",
       "        [-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.34979551,  0.43185661],\n",
       "        [-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.34979551,  0.43185661],\n",
       "        ...,\n",
       "        [-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.34979551,  0.43185661],\n",
       "        [-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.33084064,  0.43185661],\n",
       "        [-0.52433825, -0.45007681, -0.45536366, ..., -0.52433825,\n",
       "         -0.33084064,  0.43185661]],\n",
       "\n",
       "       [[-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        ...,\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.4129784 , -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.4129784 , -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.4129784 , -0.52433825],\n",
       "        ...,\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.4129784 , -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.4129784 , -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.42087626, -0.52433825]],\n",
       "\n",
       "       [[-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        ...,\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44220049, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.44299027, -0.52433825]],\n",
       "\n",
       "       [[-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43667199, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43667199, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43667199, -0.52433825],\n",
       "        ...,\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43272306, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43272306, -0.52433825],\n",
       "        [-0.52433825, -0.52433825, -0.52433825, ..., -0.52433825,\n",
       "         -0.43272306, -0.52433825]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainz = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_trainz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzjV3JfBuyuU",
    "outputId": "35167475-06d3-470f-b8e7-8c787e3b99a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609],\n",
       "        [ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609],\n",
       "        [ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609],\n",
       "        ...,\n",
       "        [ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609],\n",
       "        [ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609],\n",
       "        [ 6.16927856, -0.29609609, -0.28211854, ..., -0.29609609,\n",
       "         -0.29609609, -0.29609609]],\n",
       "\n",
       "       [[ 6.63109103, -0.29609609, -0.2770358 , ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609],\n",
       "        [ 6.47715354, -0.29609609, -0.27322374, ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609],\n",
       "        [ 6.47715354, -0.29609609, -0.27322374, ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609],\n",
       "        ...,\n",
       "        [ 6.47715354, -0.29609609, -0.27322374, ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609],\n",
       "        [ 6.47715354, -0.29609609, -0.27322374, ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609],\n",
       "        [ 6.47715354, -0.29609609, -0.27322374, ..., -0.29609609,\n",
       "         -0.03809802, -0.29609609]],\n",
       "\n",
       "       [[ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609],\n",
       "        [ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609],\n",
       "        [ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609],\n",
       "        ...,\n",
       "        [ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609],\n",
       "        [ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609],\n",
       "        [ 5.70746608, -0.29609609, -0.23256178, ..., -0.29609609,\n",
       "         -0.18243261, -0.29609609]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609],\n",
       "        [-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609],\n",
       "        [-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609],\n",
       "        ...,\n",
       "        [-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609],\n",
       "        [-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609],\n",
       "        [-0.29609609, -0.29609609, -0.29609609, ..., -0.29609609,\n",
       "         -0.05974821, -0.29609609]],\n",
       "\n",
       "       [[ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609],\n",
       "        [ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609],\n",
       "        [ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609],\n",
       "        ...,\n",
       "        [ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609],\n",
       "        [ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609],\n",
       "        [ 4.16809117, -0.29609609, -0.19952394, ..., -0.29609609,\n",
       "         -0.1319155 , -0.29609609]],\n",
       "\n",
       "       [[ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.19686606, -0.29609609],\n",
       "        [ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.14454478, -0.29609609],\n",
       "        [ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.14454478, -0.29609609],\n",
       "        ...,\n",
       "        [ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.14454478, -0.29609609],\n",
       "        [ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.19686606, -0.29609609],\n",
       "        [ 7.246841  , -0.29609609, -0.27068237, ..., -0.29609609,\n",
       "         -0.14454478, -0.29609609]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testz = (X_test - np.mean(X_test))/np.std(X_test)\n",
    "X_testz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JWr_fXpuyup",
    "outputId": "e2324ade-e1a6-4edb-a13f-3d1517fb90ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 100)               41400     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 41,501\n",
      "Trainable params: 41,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5270 samples, validate on 1317 samples\n",
      "Epoch 1/30\n",
      "5270/5270 [==============================] - 11s 2ms/step - loss: 0.2269 - acc: 0.6528 - val_loss: 0.2465 - val_acc: 0.5740\n",
      "Epoch 2/30\n",
      "5270/5270 [==============================] - 10s 2ms/step - loss: 0.2220 - acc: 0.6577 - val_loss: 0.2456 - val_acc: 0.5740\n",
      "Epoch 3/30\n",
      "5270/5270 [==============================] - 10s 2ms/step - loss: 0.2220 - acc: 0.6562 - val_loss: 0.2450 - val_acc: 0.5740\n",
      "Epoch 4/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2283 - acc: 0.6457 - val_loss: 0.2445 - val_acc: 0.5740\n",
      "Epoch 5/30\n",
      "5270/5270 [==============================] - 8s 2ms/step - loss: 0.2291 - acc: 0.6438 - val_loss: 0.2475 - val_acc: 0.5740\n",
      "Epoch 6/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2251 - acc: 0.6529 - val_loss: 0.2459 - val_acc: 0.5710\n",
      "Epoch 7/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2229 - acc: 0.6577 - val_loss: 0.2456 - val_acc: 0.5740\n",
      "Epoch 8/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2232 - acc: 0.6564 - val_loss: 0.2545 - val_acc: 0.5740\n",
      "Epoch 9/30\n",
      "5270/5270 [==============================] - 8s 2ms/step - loss: 0.2230 - acc: 0.6562 - val_loss: 0.2471 - val_acc: 0.5664\n",
      "Epoch 10/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2223 - acc: 0.6546 - val_loss: 0.2476 - val_acc: 0.5725\n",
      "Epoch 11/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2223 - acc: 0.6583 - val_loss: 0.2473 - val_acc: 0.5664\n",
      "Epoch 12/30\n",
      "5270/5270 [==============================] - 8s 2ms/step - loss: 0.2218 - acc: 0.6590 - val_loss: 0.2453 - val_acc: 0.5718\n",
      "Epoch 13/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2218 - acc: 0.6541 - val_loss: 0.2473 - val_acc: 0.5710\n",
      "Epoch 14/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2220 - acc: 0.6586 - val_loss: 0.2483 - val_acc: 0.5725\n",
      "Epoch 15/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2218 - acc: 0.6586 - val_loss: 0.2464 - val_acc: 0.5695\n",
      "Epoch 16/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2223 - acc: 0.6575 - val_loss: 0.2473 - val_acc: 0.5725\n",
      "Epoch 17/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2219 - acc: 0.6581 - val_loss: 0.2458 - val_acc: 0.5725\n",
      "Epoch 18/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2217 - acc: 0.6596 - val_loss: 0.2460 - val_acc: 0.5740\n",
      "Epoch 19/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2214 - acc: 0.6586 - val_loss: 0.2466 - val_acc: 0.5680\n",
      "Epoch 20/30\n",
      "5270/5270 [==============================] - 10s 2ms/step - loss: 0.2218 - acc: 0.6592 - val_loss: 0.2459 - val_acc: 0.5725\n",
      "Epoch 21/30\n",
      "5270/5270 [==============================] - 10s 2ms/step - loss: 0.2212 - acc: 0.6588 - val_loss: 0.2498 - val_acc: 0.5725\n",
      "Epoch 22/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2213 - acc: 0.6594 - val_loss: 0.2485 - val_acc: 0.5664\n",
      "Epoch 23/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2209 - acc: 0.6607 - val_loss: 0.2452 - val_acc: 0.5718\n",
      "Epoch 24/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2205 - acc: 0.6602 - val_loss: 0.2473 - val_acc: 0.5642\n",
      "Epoch 25/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2212 - acc: 0.6556 - val_loss: 0.2475 - val_acc: 0.5649\n",
      "Epoch 26/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2206 - acc: 0.6590 - val_loss: 0.2539 - val_acc: 0.5125\n",
      "Epoch 27/30\n",
      "5270/5270 [==============================] - 10s 2ms/step - loss: 0.2206 - acc: 0.6592 - val_loss: 0.2483 - val_acc: 0.5672\n",
      "Epoch 28/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2198 - acc: 0.6581 - val_loss: 0.2481 - val_acc: 0.5657\n",
      "Epoch 29/30\n",
      "5270/5270 [==============================] - 9s 2ms/step - loss: 0.2198 - acc: 0.6588 - val_loss: 0.2476 - val_acc: 0.5718\n",
      "Epoch 30/30\n",
      "5270/5270 [==============================] - 11s 2ms/step - loss: 0.2193 - acc: 0.6594 - val_loss: 0.2485 - val_acc: 0.5725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ca01b4908>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "modelGRU = Sequential()\n",
    "modelGRU.add(GRU(100, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, reset_after=False,input_shape=(25, 37)))\n",
    "modelGRU.add(Dense(1, activation='sigmoid'))\n",
    "modelGRU.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "print(modelGRU.summary())\n",
    "modelGRU.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZmHx-usuyvA",
    "outputId": "72605eec-14a1-49de-ea39-df2b13e823d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 [==============================] - 1s 560us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.12680334318924"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = modelGRU.evaluate(X_testz, Y_test)\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFsPDH5vuyvM"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxk5OCO6uyvZ"
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "class LSTM(object):\n",
    "    def __init__(self):\n",
    "        # define lower bound of benchmark function\n",
    "        self.Lower = 0\n",
    "        # define upper bound of benchmark function\n",
    "        self.Upper = 1\n",
    "\n",
    "    # function which returns evaluate function\n",
    "    def function(self):\n",
    "        def evalute(D,sol):\n",
    "            sol = np.array(sol)\n",
    "            sol = sigmoid(sol)\n",
    "            print(sol)\n",
    "            #display(sol)\n",
    "            op = sol>=0.50\n",
    "            X_tr = X_train[:,:,op]\n",
    "            X_te = X_test[:,:,op]\n",
    "            print(op)\n",
    "            from keras.models import Sequential\n",
    "            from keras.layers import GRU,Dense,LSTM,TimeDistributed\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(37, input_shape=(25, 37),return_sequences=True))\n",
    "            model.add(TimeDistributed(Dense(1)))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "            model.fit(X_tr, Y_train, validation_data=(X_te, Y_test), epochs=3,batch_size=50,verbose=0)\n",
    "            scores = model.evaluate(X_te, Y_test, verbose=0)\n",
    "            print(scores)\n",
    "            k = -1*scores[1]\n",
    "            return k\n",
    "        return evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4636
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 514911,
     "status": "error",
     "timestamp": 1558600421766,
     "user": {
      "displayName": "Raj Kuwar Gupta",
      "photoUrl": "https://lh4.googleusercontent.com/-2j8EEf8d9a8/AAAAAAAAAAI/AAAAAAAAD4A/4-La8lzyNq8/s64/photo.jpg",
      "userId": "15544042194427633848"
     },
     "user_tz": -330
    },
    "id": "Vs33FeSguyvh",
    "outputId": "39e826d0-a5ec-4d89-cec1-087d51e9e321",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60435648 0.55652579 0.51290082 0.55313473 0.62771598 0.62483347\n",
      " 0.57277219 0.5246291  0.66456548 0.68490907 0.62404571 0.63458407\n",
      " 0.71355039 0.65978897 0.51923699 0.70869549 0.72813613 0.55711038\n",
      " 0.72236398 0.51465741 0.5515607  0.57471537 0.55662697 0.58766809\n",
      " 0.55592764 0.50812924 0.57565023 0.58150564 0.57464121 0.71750048\n",
      " 0.5901073  0.62714198 0.52404396 0.55072019 0.65157123 0.72013204\n",
      " 0.71331529]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24558566118065117, 0.574031890751108]\n",
      "[0.5216684  0.56046179 0.67827447 0.68941771 0.5780872  0.71256205\n",
      " 0.57794584 0.60878305 0.64560053 0.57309581 0.62403119 0.72276823\n",
      " 0.72456377 0.68883632 0.67177508 0.66071236 0.66581959 0.56865665\n",
      " 0.52348191 0.59864459 0.68054883 0.62070669 0.66999382 0.55349603\n",
      " 0.57621251 0.72622379 0.68728721 0.54374439 0.62375554 0.70823859\n",
      " 0.70478192 0.52488575 0.72573951 0.52716112 0.5558945  0.57684786\n",
      " 0.67733081]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2456820744316779, 0.570994684980417]\n",
      "[0.50358527 0.57520725 0.55811928 0.54034362 0.54570889 0.70529021\n",
      " 0.6644691  0.59757298 0.62858278 0.62855839 0.52503502 0.57221559\n",
      " 0.55000873 0.7083328  0.64605718 0.70781899 0.68445263 0.54750915\n",
      " 0.55555978 0.71304479 0.72716867 0.70292288 0.57346225 0.59665766\n",
      " 0.69141683 0.62799124 0.57701907 0.56721365 0.60876108 0.63151646\n",
      " 0.67153016 0.66243556 0.59291649 0.68266733 0.71527484 0.55638773\n",
      " 0.70797949]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2463994097917842, 0.574031890751108]\n",
      "[0.64703775 0.67879293 0.52805703 0.70405448 0.72962449 0.70474019\n",
      " 0.63927744 0.63335397 0.71101772 0.55105    0.67207006 0.64605692\n",
      " 0.54187474 0.53348586 0.69867955 0.5142112  0.69636184 0.6746804\n",
      " 0.54274408 0.64798725 0.72093046 0.62754495 0.61729105 0.70326531\n",
      " 0.54759224 0.66924363 0.51615231 0.64167332 0.64311606 0.6778397\n",
      " 0.51761065 0.64262579 0.64151141 0.68070175 0.67641059 0.66248281\n",
      " 0.50089868]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2452947010732367, 0.574031890751108]\n",
      "[0.7038306  0.53025143 0.67987242 0.55726674 0.63791765 0.67697498\n",
      " 0.68348793 0.6018365  0.62354259 0.71605892 0.67590527 0.66697016\n",
      " 0.59566536 0.57846322 0.59225072 0.64926871 0.52389577 0.67128377\n",
      " 0.6700671  0.61093348 0.62293642 0.7237314  0.64861457 0.67296346\n",
      " 0.5794324  0.63814169 0.69808872 0.51688399 0.7261191  0.52533906\n",
      " 0.52372483 0.65297972 0.68496193 0.67394659 0.67944516 0.69328218\n",
      " 0.65581441]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24619443996349066, 0.574031890751108]\n",
      "[0.58938789 0.70673163 0.56645339 0.66243125 0.59531644 0.55241875\n",
      " 0.52488761 0.53712643 0.51141273 0.6653664  0.62819525 0.66184176\n",
      " 0.59022076 0.72021951 0.51537547 0.53466537 0.52916098 0.71318766\n",
      " 0.523379   0.68447276 0.70387337 0.5131167  0.68862362 0.67876666\n",
      " 0.6167254  0.64558083 0.60686957 0.5514486  0.59626954 0.5065652\n",
      " 0.66259613 0.57964387 0.60178995 0.51495468 0.56200382 0.68699679\n",
      " 0.69094973]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24574950624797592, 0.574031890751108]\n",
      "[0.55298351 0.56423944 0.53934468 0.53103703 0.63158754 0.5055293\n",
      " 0.6360656  0.71651187 0.54458238 0.69540247 0.72059766 0.53983959\n",
      " 0.57774503 0.53889408 0.60293507 0.57025056 0.57198877 0.69371487\n",
      " 0.71655432 0.50654052 0.5779412  0.61977111 0.607686   0.63612029\n",
      " 0.59200517 0.65809885 0.5869003  0.71437082 0.51065651 0.58440607\n",
      " 0.68884729 0.64741532 0.57092356 0.59958546 0.60869165 0.67199623\n",
      " 0.7256899 ]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2457909318607869, 0.574031890751108]\n",
      "[0.50348558 0.71776589 0.6008163  0.64216799 0.6848137  0.6323132\n",
      " 0.59329596 0.69262363 0.54201494 0.50815598 0.65007134 0.59475588\n",
      " 0.70483485 0.59149079 0.70289391 0.53593943 0.61876871 0.64014502\n",
      " 0.62787407 0.59238656 0.61891894 0.56135132 0.65490193 0.70434892\n",
      " 0.6850794  0.65334649 0.70518644 0.65424574 0.53549429 0.63294624\n",
      " 0.71471774 0.66520497 0.54108362 0.61454435 0.5653063  0.62736281\n",
      " 0.54263625]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24575720703683301, 0.574031890751108]\n",
      "[0.70823008 0.61993022 0.70222547 0.56662803 0.53986126 0.69471528\n",
      " 0.66817636 0.50272106 0.59002959 0.6357483  0.67777971 0.65704814\n",
      " 0.58534888 0.69627984 0.6185918  0.57448947 0.62933094 0.67663331\n",
      " 0.5334974  0.58105334 0.68485374 0.51039189 0.65532825 0.59606425\n",
      " 0.72789281 0.62576508 0.72348394 0.66552728 0.53697517 0.62320062\n",
      " 0.69846045 0.53962441 0.60083111 0.57673672 0.6465933  0.55819561\n",
      " 0.63972833]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24608702432638602, 0.574031890751108]\n",
      "[0.56052169 0.55260493 0.68406842 0.59759491 0.65716422 0.60197219\n",
      " 0.61951757 0.53046986 0.58895393 0.7264867  0.56561236 0.64270612\n",
      " 0.51073734 0.72583899 0.56792968 0.63621319 0.71695459 0.60647196\n",
      " 0.71961596 0.67366198 0.50538803 0.72360042 0.63999921 0.57709139\n",
      " 0.58733321 0.70690153 0.68666382 0.64265962 0.66894225 0.58839914\n",
      " 0.64341085 0.59477448 0.51524955 0.72184086 0.55386183 0.54903552\n",
      " 0.68666505]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24587261688102804, 0.574031890751108]\n",
      "[0.65189861 0.71366617 0.51184117 0.66960287 0.66654738 0.70183926\n",
      " 0.58353174 0.52703613 0.55643464 0.65436043 0.65343407 0.70880789\n",
      " 0.51729932 0.71009126 0.68456916 0.54159383 0.60852121 0.7268658\n",
      " 0.72872215 0.65865297 0.70864703 0.53901241 0.53834424 0.57910397\n",
      " 0.55712167 0.70665257 0.6067026  0.62986755 0.69509023 0.72497017\n",
      " 0.51645342 0.55663728 0.63053423 0.52271273 0.64365416 0.71262872\n",
      " 0.58443521]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2457222842590865, 0.574031890751108]\n",
      "[0.5067416  0.61567236 0.70818549 0.65431944 0.56460604 0.63645314\n",
      " 0.63355461 0.54713932 0.68421124 0.56989998 0.69963575 0.62538086\n",
      " 0.56761813 0.67087915 0.57462909 0.70977702 0.72593137 0.66688727\n",
      " 0.56496093 0.52933176 0.59423103 0.65739176 0.56043    0.70741904\n",
      " 0.65113709 0.66995877 0.55993751 0.6093069  0.68735201 0.5377561\n",
      " 0.57086889 0.7304643  0.52770633 0.57157694 0.53960355 0.504577\n",
      " 0.70460447]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24554908956735536, 0.574031890751108]\n",
      "[0.53653644 0.5453408  0.59005261 0.68347308 0.60249705 0.51819656\n",
      " 0.50225182 0.63980327 0.51344648 0.72235441 0.52284478 0.7153963\n",
      " 0.54900626 0.61518515 0.62322296 0.67917927 0.7081647  0.6567324\n",
      " 0.72202624 0.57361873 0.72162064 0.67940411 0.50773867 0.70192578\n",
      " 0.71843264 0.60232719 0.57969133 0.51952568 0.59153611 0.64068067\n",
      " 0.70374825 0.64884225 0.60842827 0.6007863  0.6090932  0.66144734\n",
      " 0.57566838]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24663665925768533, 0.574031890751108]\n",
      "[0.68904207 0.68545545 0.58482142 0.57210323 0.57971562 0.71036972\n",
      " 0.69570503 0.64837691 0.62216329 0.68517761 0.51970966 0.72745899\n",
      " 0.51768777 0.67618237 0.70554007 0.60836846 0.66768573 0.62256824\n",
      " 0.65390015 0.61452328 0.51179664 0.62244658 0.58420608 0.72394833\n",
      " 0.55613007 0.6781254  0.68400807 0.72174315 0.61038818 0.70406898\n",
      " 0.55585005 0.6825846  0.65607862 0.61495571 0.65751797 0.70867663\n",
      " 0.67024683]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.2458617207265389, 0.574031890751108]\n",
      "[0.52970262 0.63339048 0.58821399 0.68851016 0.534584   0.66709148\n",
      " 0.64645923 0.6166235  0.65581761 0.6062246  0.53442544 0.70363923\n",
      " 0.66374529 0.61273974 0.67164646 0.62352939 0.54826931 0.52841266\n",
      " 0.56990738 0.57181979 0.52829933 0.53963376 0.67892931 0.5121907\n",
      " 0.7279779  0.59823332 0.55005914 0.71711904 0.67217038 0.72733949\n",
      " 0.53280876 0.66515446 0.58487276 0.72440315 0.59052157 0.64324567\n",
      " 0.68271559]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24480117498787407, 0.574031890751108]\n",
      "[0.68087318 0.69594378 0.69253106 0.58035521 0.52081746 0.65576699\n",
      " 0.52727841 0.65095239 0.63182    0.56186667 0.54822756 0.5223994\n",
      " 0.56146727 0.52715322 0.55249702 0.51456749 0.54990881 0.71209677\n",
      " 0.55923522 0.53399845 0.50786114 0.65246451 0.64262139 0.70493409\n",
      " 0.57567001 0.57406438 0.71454371 0.65871211 0.65258517 0.5473545\n",
      " 0.53729274 0.50133716 0.61214125 0.72377263 0.70673104 0.65737407\n",
      " 0.52561777]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24703706360804645, 0.574031890751108]\n",
      "[0.6303146  0.53094616 0.58470251 0.64953655 0.654022   0.71411795\n",
      " 0.63031636 0.51099118 0.72335782 0.5465811  0.65512139 0.62169315\n",
      " 0.71401338 0.71892632 0.70821005 0.73103188 0.50270343 0.56752833\n",
      " 0.62599387 0.6113998  0.5102527  0.50418077 0.7086443  0.72178244\n",
      " 0.55862177 0.61589564 0.6743141  0.5244083  0.67398333 0.50196791\n",
      " 0.6712251  0.60784607 0.52203852 0.54579397 0.51591273 0.71386998\n",
      " 0.60852828]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24542886957854326, 0.574031890751108]\n",
      "[0.69276312 0.72669472 0.67892711 0.67522071 0.63440992 0.58028159\n",
      " 0.54355055 0.67082973 0.5293196  0.55740591 0.52622181 0.60287645\n",
      " 0.56801679 0.70523734 0.67619216 0.55344103 0.5440846  0.69306959\n",
      " 0.64466396 0.64989979 0.57166077 0.70785498 0.64081926 0.54361402\n",
      " 0.52604432 0.68141564 0.72652715 0.71737461 0.7028435  0.65735098\n",
      " 0.72040131 0.72520912 0.58691258 0.5437892  0.68170476 0.7056839\n",
      " 0.66175343]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24643550882216375, 0.574031890751108]\n",
      "[0.63092948 0.64968438 0.53676344 0.66330021 0.50907625 0.67893303\n",
      " 0.53381709 0.6912856  0.51360957 0.68108395 0.57739554 0.57905128\n",
      " 0.57122169 0.53046517 0.64043607 0.67323366 0.56028403 0.69995043\n",
      " 0.51378499 0.68601613 0.53367102 0.70190467 0.57523677 0.53319849\n",
      " 0.62671887 0.65409715 0.54558679 0.71817888 0.66332207 0.68910061\n",
      " 0.51931752 0.70290142 0.64487522 0.61918896 0.5718874  0.67340903\n",
      " 0.62664356]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[0.24541970955076414, 0.5725132878657626]\n",
      "[0.63917693 0.54233797 0.60769513 0.69713655 0.52654637 0.72416144\n",
      " 0.50164884 0.56083858 0.67304119 0.58430494 0.65777319 0.54091445\n",
      " 0.72148736 0.54787873 0.68726472 0.55462209 0.7231467  0.6083028\n",
      " 0.62093247 0.53430047 0.55061949 0.55857068 0.72391281 0.71306519\n",
      " 0.70368725 0.68901592 0.56139436 0.6335958  0.69029897 0.63802757\n",
      " 0.63996435 0.66855532 0.52799648 0.64819865 0.63979907 0.66566808\n",
      " 0.69104773]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3d189f611e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m370\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnFES\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQmax\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/NiaPy/algorithms/basic/ba.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_bat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/NiaPy/algorithms/basic/ba.py\u001b[0m in \u001b[0;36mmove_bat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_bat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_flag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/NiaPy/algorithms/basic/ba.py\u001b[0m in \u001b[0;36minit_bat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFitness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_bat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-50d9ab610dfd>\u001b[0m in \u001b[0;36mevalute\u001b[0;34m(D, sol)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from NiaPy.algorithms.basic import BatAlgorithm\n",
    "for i in range(5):\n",
    "    algorithm = BatAlgorithm(D=37, NP=370, nFES=5,A = 0.5,r=0.5,Qmin=0.0,Qmax =2.0, benchmark=LSTM())\n",
    "    best = algorithm.run()\n",
    "    print(best[1]*-100)\n",
    "    ans.append(-1*best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgBEA4hiuyvw",
    "outputId": "9bab0ca8-1d23-43bf-c8fb-0e2429d29fcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.574031890751108,\n",
       " 0.5717539864230898,\n",
       " 0.5717539864230898,\n",
       " 0.5702353835377444,\n",
       " 0.5732725893084353]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Lfoks-Z1i4z"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from scipy.spatial.distance import euclidean\n",
    "from numpy import full, apply_along_axis, argmin, copy, sum, inf, fmax, pi, where\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('NiaPy.algorithms.basic')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "__all__ = ['GlowwormSwarmOptimization', 'GlowwormSwarmOptimizationV1', 'GlowwormSwarmOptimizationV2', 'GlowwormSwarmOptimizationV3']\n",
    "\n",
    "class GlowwormSwarmOptimization():\n",
    "\tr\"\"\"Implementation of glowwarm swarm optimization.\n",
    "\t**Algorithm:** Glowwarm Swarm Optimization Algorithm\n",
    "\t**Date:** 2018\n",
    "\t**Authors:** Klemen Berkovič\n",
    "\t**License:** MIT\n",
    "\t**Reference URL:** https://www.springer.com/gp/book/9783319515946\n",
    "\t**Reference paper:** Kaipa, Krishnanand N., and Debasish Ghose. Glowworm swarm optimization: theory, algorithms, and applications. Vol. 698. Springer, 2017.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self,D, l0,nt,rho,gamma,beta,s,lower,upper):\n",
    "\t\tself.D, self.n, self.l0, self.nt, self.rho, self.gamma, self.beta, self.s,self.Lower,self.Upper = D,n, l0, nt, rho, gamma, beta, s,lower,upper\n",
    "    self.bRange = self.Upper - self.Lower\n",
    "\n",
    "\tdef randMove(self, i):\n",
    "\t\tj = i\n",
    "\t\twhile i == j: j = self.randint(self.n)\n",
    "\t\treturn j\n",
    "\n",
    "\tdef getNeighbors(self, i, r, GS, L):\n",
    "\t\tN = full(self.n, 0)\n",
    "\t\tfor j, gw in enumerate(GS): N[j] = 1 if i != j and euclidean(GS[i], gw) <= r and L[i] >= L[j] else 0\n",
    "\t\treturn N\n",
    "\n",
    "\tdef probabilityes(self, i, N, L):\n",
    "\t\td, P = sum(L[where(N == 1)] - L[i]), full(self.n, .0)\n",
    "\t\tfor j in range(self.n): P[i] = ((L[j] - L[i]) / d) if N[j] == 1 else 0\n",
    "\t\treturn P\n",
    "\n",
    "\tdef moveSelect(self, pb, i):\n",
    "\t\tr, b_l, b_u = self.rand(), 0, 0\n",
    "\t\tfor j in range(self.n):\n",
    "\t\t\tb_l, b_u = b_u, b_u + pb[i]\n",
    "\t\t\tif b_l < r < b_u: return j\n",
    "\t\treturn self.randint(self.n)\n",
    "\n",
    "\tdef calcLuciferin(self, L, GS_f): return (1 - self.rho) * L + self.gamma * GS_f\n",
    "\n",
    "\tdef rangeUpdate(self, R, N, rs): return R + self.beta * (self.nt - sum(N))\n",
    "\n",
    "\tdef getBest(self, GS, GS_f, xb, xb_f):\n",
    "\t\tib = argmin(GS_f)\n",
    "\t\tif GS_f[ib] < xb_f: return GS[ib], GS_f[ib]\n",
    "\t\telse: return xb, xb_f\n",
    "\n",
    "\tdef runTask(self):\n",
    "\t\trs = euclidean(full(self.D, 0), self.bRange)\n",
    "\t\tGS, GS_f, L, R = self.uniform(self.Lower, self.Upper, [self.n, self.D]), full(self.n, inf), full(self.n, self.l0), full(self.n, rs)\n",
    "\t\txb, xb_f = None, inf\n",
    "\t\tfor i in range(5):\n",
    "\t\t\tGSo, Ro, GS_f = copy(GS), copy(R), apply_along_axis(task.eval, 1, GS)\n",
    "\t\t\txb, xb_f = self.getBest(GS, GS_f, xb, xb_f)\n",
    "\t\t\tL = self.calcLuciferin(L, GS_f)\n",
    "\t\t\tN = [self.getNeighbors(i, Ro[i], GSo, L) for i in range(self.n)]\n",
    "\t\t\tP = [self.probabilityes(i, N[i], L) for i in range(self.n)]\n",
    "\t\t\tj = [self.moveSelect(P[i], i) for i in range(self.n)]\n",
    "\t\t\tfor i in range(self.n): GS[i] = task.repair(GSo[i] + self.s * ((GSo[j[i]] - GSo[i]) / (euclidean(GSo[j[i]], GSo[i]) + 1e-31)))\n",
    "\t\t\tfor i in range(self.n): R[i] = max(0, min(rs, self.rangeUpdate(Ro[i], N[i], rs)))\n",
    "\t\treturn xb, xb_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ilUl2nEAZtX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "import random\n",
    "\n",
    "def Fun(D, sol):\n",
    "    sol = np.array(sol)\n",
    "    #print(sol)\n",
    "    sol = sigmoid(sol)\n",
    "    op = sol>=0.6\n",
    "    #print(op)\n",
    "    X_tr = X_train_tf[:,op]\n",
    "    X_valid = X_valid_tf[:,op]\n",
    "    print(X_valid.shape)\n",
    "    model=LogisticRegression(C = 0.01, penalty = 'l2', solver = 'lbfgs' , random_state = 42)\n",
    "    model.fit(X_tr, y_train)\n",
    "    y_train_preds = model.predict_proba(X_tr)[:,1]\n",
    "    y_valid_preds = model.predict_proba(X_valid)[:,1]\n",
    "    auc_train = roc_auc_score(y_train, y_train_preds)\n",
    "    auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
    "    print(f'auc_valid ={auc_valid}')\n",
    "    k = -1*(auc_valid)\n",
    "    return k"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "bat_and_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

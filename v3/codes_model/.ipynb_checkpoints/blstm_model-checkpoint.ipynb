{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/patient_data_4830_hours.csv')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3D = np.array(df.drop(['SUBJECT_ID', 'TimeStamp'], 1))\n",
    "matrix3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3D = np.array(matrix3D).reshape((6587, 98, 37))\n",
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = []\n",
    "for k in range(37):\n",
    "    h = (sum(sum(matrix3D[:,:,k])))\n",
    "    if int(h)==0:\n",
    "        g.append(False)\n",
    "    else:\n",
    "        g.append(True)\n",
    "g = np.array(g)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3D = matrix3D[:,:,g]\n",
    "matrix3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = pd.read_csv('../input/outcomes.csv')\n",
    "outcomes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(outcomes.drop(['SUBJECT_ID'], 1))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrix3D\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X,X))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate((Y,Y))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X,X))\n",
    "X = np.concatenate((X,X))\n",
    "X = np.concatenate((X,X))\n",
    "display(X.shape)\n",
    "Y = np.concatenate((Y,Y))\n",
    "Y = np.concatenate((Y,Y))\n",
    "Y = np.concatenate((Y,Y))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X.reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = Y.reshape(Y.shape[0],1,Y.shape[1])\n",
    "print(Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.insert(X_new, 1, Y_new, axis=1)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_new)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:,0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_new[:,1]\n",
    "Y = Y[:,0]\n",
    "Y = Y[:,0]\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:95000]\n",
    "X_test = X[95000:]\n",
    "Y_train = Y[:95000]\n",
    "Y_test = Y[95000:]\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout,Bidirectional,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb = Sequential()\n",
    "modelb.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "modelb.add(Bidirectional(LSTM(25),merge_mode='sum'))\n",
    "modelb.add(Dropout(0.2))\n",
    "#modelb.add(BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "modelb.add(Dense(100,activation='tanh'))\n",
    "modelb.add(Dense(25,activation='tanh'))\n",
    "modelb.add(Dense(10,activation='tanh'))\n",
    "modelb.add(Dense(1, activation='sigmoid'))\n",
    "modelb.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "print(modelb.summary())\n",
    "historyb = modelb.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,batch_size=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresb = modelb.evaluate(X_test, Y_test)\n",
    "scoresb[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score, f1_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 1.0 - roc_auc_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "display(score)\n",
    "\n",
    "\n",
    "f_score=f1_score(Y_test,y_pred.round())\n",
    "\n",
    "display(f_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prfs=precision_recall_fscore_support(Y_test,y_pred.round())\n",
    "\n",
    "\n",
    "display(prfs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_score_micro=f1_score(Y_test,y_pred.round(),average='micro')\n",
    "f_score_macro=f1_score(Y_test,y_pred.round(),average='macro')\n",
    "\n",
    "display(f_score_micro)\n",
    "display(f_score_macro)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf=confusion_matrix(Y_test,y_pred.round())\n",
    "\n",
    "display(cf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUC : \"+str(1.0 - score)+\",  Score/Loss : \"+str(score)+\", F1_Score_average: \"+str(f_score)+\", Precision, Recall, F1_score, Support: \"+str(prfs))\n",
    "print(\"F1_score_micro: \"+str(f_score_micro))\n",
    "print(\"F1_score_macro: \"+str(f_score_macro))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cf)\n",
    "print(\"END\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# In[271]:\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[1], tpr[1], _ = roc_curve(Y_test[:, 0], y_pred[:, 0])\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])\n",
    "\n",
    "\n",
    "# In[272]:\n",
    "\n",
    "\n",
    "display(roc_auc)\n",
    "\n",
    "\n",
    "# In[275]:\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(historyb.history['acc'])\n",
    "plt.plot(historyb.history['val_acc'])\n",
    "plt.title('Model accuracy BLSTM')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(historyb.history['loss'])\n",
    "plt.plot(historyb.history['val_loss'])\n",
    "plt.title('Model loss BLSTM')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
